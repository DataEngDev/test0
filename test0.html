<!DOCTYPE html>
<html>
<!-- Prez mode:

    Run KeyRemap4MacBook.
    Enable presentation settings at the top.

-->

<!-- TO DO:  {{{

    * Content
    - Something to replace the hidden Approaches section
    - Most common question: how do I convince my team to test?

    * Layout
    - URL footer on first few slides.



    # Getting Started Testing

    - Goal
        - Give you tools to start testing your code

    - Two challenges:
        - People
        - Code

    - Vegetables

    = People

    - Why test?
        - Best way to know if your code works
    - Resistance
        - More work
        - Hard to add to a legacy project
        - Not a developer's job?
    - Benefits
        - Confidence
        - Turns fear into boredom
        - Faster in the long run
    - Fighting Chaos!
    - How to start
        - Start with the easy
        - Start with the necessary

    = Code

    - 2 vs 3

    - How to write tests
        - Show *a* way to do it.
        - there are many techniques

    = First principles

    - Product code: stock portfolio

    - First test: interactive

    - Second test: standalone

    - Third test: with expected results

    - Fourth test: check results automatically

    - Getting complicated!

    = Unittest

    - unittest
        - stdlib
        - a good solid foundation
        - not the only way to do it
        - not about unit vs integration

    - Simple unit test

    = Test Doubles


    = Other stuff
    - doctest
    - coverage
    - nose, py.test, trial
    - lettuce
    - Selenium
    - ddt
    - TDD

}}} -->
<!-- *** Head stuff {{{ -->
<!--[[[cog
import cog
from cogutil import *
]]]-->
<!--[[[end]]]-->
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <!-- Slide meta data, remove/edit as you see fit -->
    <title>Getting Started Testing</title>

    <!-- Slippy core file and dependencies -->
    <script type="text/javascript" src="slippy/jquery.min.js"></script>
    <script type="text/javascript" src="slippy/jquery.history.js"></script>
    <!-- Slippy slides -->
    <script type="text/javascript" src="slippy/slippy.js"></script>
    <script type="text/javascript" src="typogr.min.js"></script>

    <link type="text/css" rel="stylesheet" href="slippy/slippy.css"/>
    <link type="text/css" rel="stylesheet" href="slippy/slippy-pure.css"/>
    <!-- Our styles -->
    <link type="text/css" rel="stylesheet" href="slides.css"/>

    <!-- Highlight, for syntax coloring. -->
    <script type="text/javascript" src="highlight/highlight.pack.js"></script>
    <link rel="stylesheet" href="highlight/vs.css">

    <!-- Ned's slides init code -->
    <script type="text/javascript" src="lineselect.js"></script>

    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,600,700,800|Permanent+Marker' rel='stylesheet' type='text/css'>

    <script type="text/javascript" src="slides.js"></script>

    <!-- Custom style for this deck -->
    <style type="text/css">
        .slide li:before {
            content: "▸  ";     /* U+25B8 U+00A0 U+00A0 */
        }
        .slide li.good:before {
            content: "✓   ";    /* U+2713 U+00A0 U+00A0 */
            color: #4c4;
        }
        .slide li.bad:before {
            content: "✘   ";    /* U+2718 U+00A0 U+00A0 */
            color: #f44;
        }
        .slide li.unsure:before {
            content: "⁈  ";    /* U+203D U+00A0 U+00A0 */
            color: #44f;
        }
    </style>

</head>
<!-- }}} -->

<body class="slides">

<!-- *** Slide layouts {{{ -->

<div class="layout" data-name="clean">
    <content></content>
</div>

<div class="layout" data-name="default">
    <content></content>
    <div class="footer">
        <span class="left">bit.ly<span class='punct'>/</span>pytest2</span>
        <span class="right"><span class='punct'>@</span>nedbat</span>
        <hr class="defloat" />
    </div>
</div>

<div class="hidden_slide">
    <h1>Font test</h1>
    <ul>
        <li>This is a long sentence with many words, what do I think of it?</li>
        <li>This isn't "straight" quotes.</li>
        <li>This isn&rsquo;t &ldquo;straight&rdquo; quotes.</li>
        <li></li>
    </ul>
</div>

<!-- *** Blank slides {{{

<div class="slide">
    <h1></h1>
    <ul>
        <li></li>
        <li></li>
        <li></li>
        <li></li>
    </ul>
</div>

 }}} -->

<!-- }}} -->

<!-- *** Introduction {{{ -->

<div class="slide title" data-layout="clean">
    <h1 style="margin-top:-2em;">Getting Started Testing</h1>
    <h2>Ned Batchelder
    <br/>@nedbat
    <br/>
    <br/><span class="punct">http://</span>bit.ly<span class="punct">/</span>pytest2</h2>
</div>

<div class="slide">
    <h1>Goals</h1>
    <ul>
        <li>Show you a way to test</li>
        <li>Remove mystery</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Writing correct code is complicated, it's hard.  How do you know when
    you've gotten it right, and how do you know your code has stayed right
    even after you've changed it?</p>

    <p>The best we know to do this is with automated testing.  Testing is a
    large topic, with its own tools and techniques.  It can be
    overwhelming.</p>

    <p>In this talk, I will show you how to write automated tests to test your
    Python code.  I'll start from scratch. By the time we're done here, you
    should have a mystery-free view of the basics and even a few advanced
    techniques, of automated testing.</p>

    <p>I'll include some pointers off to more advanced or exotic techniques,
    but you will have a good set of tools if you follow the methods shown
    here.</p>

    <p>The concepts covered here work the same in Python 2 or 3, though the
    code is Python 2.  In Python 3, a few imports and module names would
    have to change.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Why test?</h1>
    <ul>
        <li>Know if your code works</li>
        <li>Save time</li>
        <li>Better code</li>
        <li>Remove fear</li>
        <li>"Debugging is hard, testing is easy"</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>My main point here isn't to convince you to test, I hope you are reading
    this because you already know you want to do it.  But I have to say at
    least a little bit about why you should test.</p>

    <p>Automated testing is the best way we know to determine if your code
    works.  There are other techniques, like manual testing, or shipping it to
    customers and waiting for complaints, but automated testing works much
    better than those ways.</p>

    <p>Although writing tests is serious effort that takes real time, in
    the long run it will let you produce software faster because it makes your
    development process more predictable, and you'll spend less time fighting
    expensive fires.</p>

    <p>Testing also gives you another view into your code, and will probably
    help you write just plain better code.  The tests force you to think about
    the structure of your code, and you will find better ways to modularize
    it.</p>

    <p>Lastly, testing removes fear, because your tests are a safety net that
    can tell you early when you have made a mistake and set you back on the
    right path.</p>

</div><!-- }}} -->

<div class="slide">
    <p class="incremental" style='font-family: "Permanent Marker"; font-size: 450%; text-align: center; color: red; margin-top:0'>I&nbsp;  AM&nbsp;  BAD!</p>
    <p class="incremental" style='font-family: "Permanent Marker"; font-size: 200%; text-align: center; color: red; margin-top:0; letter-spacing: .05em'>and I should feel bad</p>
    <p class="incremental" style='text-align: center'><img src='dadtoon-iambad-3.png' width="50%"/></p>
</div>

<div class="text"><!-- {{{ -->

    <p>If you are like most developers, you know that you should be writing
    tests, but you aren't, and you feel bad about it.  Tests are the dental
    floss of development: everyone knows they should do it more, but they
    don't, and they feel guilty about it.</p>

    <p>BTW: illustrations by my son Ben!</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Yeah, it's hard</h1>
    <ul>
        <li class="incremental">A lot of work</li>
        <li class="incremental">People (you) won't want to</li>
        <li class="incremental">But: it pays off</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>It's true, testing is not easy.  It's real engineering that takes
    real thought and hard work.  But it pays off in the end.</p>

    <p>How often have you heard someone say, "I wrote a lot of tests, but it
    wasn't worth it, so I deleted them."  They don't.  Tests are good.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Chaos!</h1>
    <p style='text-align: center; margin-top:-1em'><img src='dadtoon-chaos-2.png' width="60%"/></p>
</div>

<div class="text"><!-- {{{ -->

    <p>The fact is that developing software is a constant battle against chaos,
    in all sorts of little ways.  You carefully organize your ideas in lines of
    code, but things change.  You add extra lines later, and they don't quite
    work as you want.  New components are added to the system and your previous
    assumptions are invalidated.  The services you depended on shift
    subtly.</p>

    <p>You know the feeling: on a bad day, it seems like everything is out to
    get you, the world is populated by gremlins and monsters, and they are all
    trying to get at your code.</p>

    <p>You have to fight that chaos, and the weapon you have is automated
    tests.</p>

    <p>OK, enough of the sermon, let's talk about how to write tests.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Roadmap</h1>
    <ul>
        <li>Growing tests</li>
        <li>unittest</li>
        <li>Mocks</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>The rest of the talk is divided into three parts:</p>

    <ol>
        <li>We'll grow some tests in an ad-hoc way, examining what's good and
            bad about the style of code we get,</li>
        <li>we'll use unittest to write tests the right way,</li>
        <li>and we'll talk about a more advanced topic, mocks.</li>
    </ol>

</div><!-- }}} -->

<!-- }}} -->

<!-- *** Grow a first test {{{ -->
<div class="slide section" data-layout="clean">
    <h1>First principles</h1>
    <h2>Growing tests</h2>
</div>

<div class="text"><!-- {{{ -->

    <p>We'll start with a real (if tiny) piece of code, and start testing
    it.  First we'll do it manually, and then grow in sophistication from there,
    adding to our tests to solve problems we see along the way.</p>

    <p>Keep in mind, the first few iterations of these tests are not the good
    way to write tests.  I'll let you know when we've gotten to the right
    way!</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Stock portfolio class</h1>
    <!--[[[cog include_file("portfolio1.py") ]]] {{{ -->
    <pre class='python'>
    # portfolio1.py

    class Portfolio(object):
        """A simple stock portfolio"""
        def __init__(self):
            # stocks is a list of lists:
            #   [[name, shares, price], ...]
            self.stocks = []

        def buy(self, name, shares, price):
            """Buy `name`: `shares` shares at `price`."""
            self.stocks.append([name, shares, price])

        def cost(self):
            """What was the total cost of this portfolio?"""
            amt = 0.0
            for name, shares, price in self.stocks:
                amt += shares * price
            return amt
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>Here is our code under test, a simple stock portfolio class.  It simply
    stores the lots of stocks purchased: each is a stock name, a number of
    shares, and the price it was bought at.  We have a method to buy a stock,
    and a method that tells us the total cost of the portfolio:</p>

<!--[[[cog include_file("portfolio1.py", px=True) ]]] {{{ -->
<code lang='python'>
# portfolio1.py

class Portfolio(object):
    """A simple stock portfolio"""
    def __init__(self):
        # stocks is a list of lists:
        #   [[name, shares, price], ...]
        self.stocks = []

    def buy(self, name, shares, price):
        """Buy `name`: `shares` shares at `price`."""
        self.stocks.append([name, shares, price])

    def cost(self):
        """What was the total cost of this portfolio?"""
        amt = 0.0
        for name, shares, price in self.stocks:
            amt += shares * price
        return amt
</code>
<!--[[[end]]] }}}-->

</div><!-- }}} -->

<div class="slide">
    <h1>First test: interactive</h1>
    <!-- ** Interactive session {{{ -->
    <!--[[[cog
    prompt_session("""\
        p = Portfolio()
        p.cost()

        p.buy("IBM", 100, 176.48)
        p.cost()

        p.buy("HPQ", 100, 36.15)
        p.cost()
        """,
        prelude="""\
        from portfolio1 import Portfolio
        """)
    ]]]-->
    <pre class='python console'>
    &gt;&gt;&gt; p = Portfolio()
    &gt;&gt;&gt; p.cost()
    0.0

    &gt;&gt;&gt; p.buy("IBM", 100, 176.48)
    &gt;&gt;&gt; p.cost()
    17648.0

    &gt;&gt;&gt; p.buy("HPQ", 100, 36.15)
    &gt;&gt;&gt; p.cost()
    21263.0
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
    <li class="good">Good: testing the code</li>
    <li class="bad">Bad: not repeatable</li>
    <li class="bad">Bad: labor intensive</li>
    <li class="bad">Bad: is it right?</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>For our first test, we just run it manually in a Python prompt.  This is
    where most programmers start with testing: play around with the code and
    see if it works.</p>

    <p>Running it like this, we can see that it's right.  An empty portfolio
    has a cost of zero.  We buy one stock, and the cost is the price times the
    shares. Then we buy another, and the cost has gone up as it should.</p>

    <p>This is good, we're testing the code.  Some developers wouldn't have
    even taken this step!  But it's bad because it's not repeatable.  If
    tomorrow we make a change to this code, it's hard to make sure that we'll
    run the same tests and cover the same conditions that we did today.</p>

    <p>It's also labor intensive: we have to type these function calls each
    time we want to test the class.  And how do we know the results are right?
    We have to carefully examine the output, and get out a calculator, and see
    that the answer is what we expect.</p>

    <p>So we have one good quality, and three bad ones.  Let's improve the
    situation.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Second test: standalone</h1>
    <!--[[[cog include_file("porttest1.py")   ]]] {{{ -->
    <pre class='python'>
    # porttest1.py
    from portfolio1 import Portfolio

    p = Portfolio()
    print "Empty portfolio cost: %s" % p.cost()
    p.buy("IBM", 100, 176.48)
    print "With 100 IBM @ 176.48: %s" % p.cost()
    p.buy("HPQ", 100, 36.15)
    print "With 100 HPQ @ 36.15: %s" % p.cost()
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("porttest1.out")   ]]] {{{ -->
    <pre class='text'>
    $ python porttest1.py
      File "porttest1.py", line 5
        print "Empty portfolio cost: %s" % p.cost()
                                       ^
    SyntaxError: invalid syntax
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="good">Good: testing the code</li>
        <li class="good">Better: repeatable</li>
        <li class="good">Better: low effort</li>
        <li class="bad">Bad: is it right?</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Instead of typing code into a Python prompt, let's make a separate file
    to hold test code.  We'll do the same series of steps as before, but
    they'll be recorded in our test file, and we'll print the results we
    get:</p>

<!--[[[cog include_file("porttest1.py", px=True) ]]] {{{ -->
<code lang='python'>
# porttest1.py
from portfolio1 import Portfolio

p = Portfolio()
print "Empty portfolio cost: %s" % p.cost()
p.buy("IBM", 100, 176.48)
print "With 100 IBM @ 176.48: %s" % p.cost()
p.buy("HPQ", 100, 36.15)
print "With 100 HPQ @ 36.15: %s" % p.cost()
</code>
<!--[[[end]]] }}}-->

    <p>When we run it, we get:</p>

<!--[[[cog include_file("porttest1.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python porttest1.py
  File "porttest1.py", line 5
    print "Empty portfolio cost: %s" % p.cost()
                                   ^
SyntaxError: invalid syntax
</code>
<!--[[[end]]] }}}-->

    <p>This is better because it's repeatable, since we can run this test file
    any time we want and have the same tests run every time.  And it's low
    effort: running a file is easy and quick.</p>

    <p>But we still don't know for sure that the answers are right unless we
    peer at the numbers printed and work out each time what they are supposed
    to be.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Third test: expected results</h1>
    <!--[[[cog include_file("porttest2.py", start=4)   ]]] {{{ -->
    <pre class='python'>
    p = Portfolio()
    print "Empty portfolio cost: %s, should be 0.0" % p.cost()
    p.buy("IBM", 100, 176.48)
    print "With 100 IBM @ 176.48: %s, should be 17648.0" % p.cost()
    p.buy("HPQ", 100, 36.15)
    print "With 100 HPQ @ 36.15: %s, should be 21263.0" % p.cost()
    </pre>
    <!--[[[end]]] }}} -->
    <!--[[[cog include_file("porttest2.out")   ]]] {{{ -->
    <pre class='text'>
    $ python porttest2.py
      File "porttest2.py", line 5
        print "Empty portfolio cost: %s, should be 0.0" % p.cost()
                                                      ^
    SyntaxError: invalid syntax
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="good">Good: repeatable with low effort</li>
        <li class="good">Better: explicit expected results</li>
        <li class="bad">Bad: have to check the results yourself</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Here we've added to our test file so that in addition to printing the
    result it got, it prints the result it should have gotten:</p>

<!--[[[cog include_file("porttest2.py", px=True) ]]] {{{ -->
<code lang='python'>
# porttest2.py
from portfolio1 import Portfolio

p = Portfolio()
print "Empty portfolio cost: %s, should be 0.0" % p.cost()
p.buy("IBM", 100, 176.48)
print "With 100 IBM @ 176.48: %s, should be 17648.0" % p.cost()
p.buy("HPQ", 100, 36.15)
print "With 100 HPQ @ 36.15: %s, should be 21263.0" % p.cost()
</code>
<!--[[[end]]] }}}-->

    <p>This is better: we don't have to calculate the expected results, they
    are recorded right there in the output:</p>

<!--[[[cog include_file("porttest2.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python porttest2.py
  File "porttest2.py", line 5
    print "Empty portfolio cost: %s, should be 0.0" % p.cost()
                                                  ^
SyntaxError: invalid syntax
</code>
<!--[[[end]]] }}}-->

    <p>But we still have to examine all the output and compare the actual
    result to the expected result.  Keep in mind, the code here is very small,
    so it doesn't seem like a burden.  But in a real system, you might have
    thousands of tests.  You don't want to examine each one to see if the
    result is correct.</p>

    <p>This is still tedious work we have to do, we should get the computer to
    do it for us.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Fourth test: check results automatically</h1>
    <!--[[[cog include_file("porttest3.py", start=4)   ]]] {{{ -->
    <pre class='python'>
    p = Portfolio()
    print "Empty portfolio cost: %s, should be 0.0" % p.cost()
    assert p.cost() == 0.0
    p.buy("IBM", 100, 176.48)
    print "With 100 IBM @ 176.48: %s, should be 17648.0" % p.cost()
    assert p.cost() == 17648.0
    p.buy("HPQ", 100, 36.15)
    print "With 100 HPQ @ 36.15: %s, should be 21263.0" % p.cost()
    assert p.cost() == 21263.0
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("porttest3.out")   ]]] {{{ -->
    <pre class='text'>
    $ python porttest3.py
      File "porttest3.py", line 5
        print "Empty portfolio cost: %s, should be 0.0" % p.cost()
                                                      ^
    SyntaxError: invalid syntax
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="good">Good: repeatable with low effort</li>
        <li class="good">Good: explicit expected results</li>
        <li class="good">Good: results checked automatically</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Here we've used the Python assert statement.  You may not have run
    across this before.  It takes a condition, and evaluates whether it's
    true or not.  If it's true, then execution continues onto the next
    statement.  If the condition is false, it raises an AssertionError
    exception:</p>

<!--[[[cog include_file("porttest3.py", px=True, start=4) ]]] {{{ -->
<code lang='python'>
p = Portfolio()
print "Empty portfolio cost: %s, should be 0.0" % p.cost()
assert p.cost() == 0.0
p.buy("IBM", 100, 176.48)
print "With 100 IBM @ 176.48: %s, should be 17648.0" % p.cost()
assert p.cost() == 17648.0
p.buy("HPQ", 100, 36.15)
print "With 100 HPQ @ 36.15: %s, should be 21263.0" % p.cost()
assert p.cost() == 21263.0
</code>
<!--[[[end]]] }}}-->

    <p>So now we have the results checked automatically.  If one of the results
    is incorrect, the assert statement will raise an exception.</p>

    <p>Assertions like these are at the heart of automated testing, and you'll
    see a lot of them in real tests, though as we'll see, they take slightly
    different forms.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Fourth test: what failure looks like</h1>
    <!--[[[cog include_file("porttest3_broken.out")   ]]] {{{ -->
    <pre class='text'>
    $ python porttest3_broken.py
      File "porttest3_broken.py", line 5
        print "Empty portfolio cost: %s, should be 0.0" % p.cost()
                                                      ^
    SyntaxError: invalid syntax
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="good">Good: repeatable with low effort</li>
        <li class="good">Good: expected results checked automatically</li>
        <li class="good">OK: visible failure visible, but cluttered output</li>
        <li class="bad">Bad: failure stops tests</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>There are a couple of problems with assertions like these.  First, all
    the successful tests clutter up the output.  You may think it's good to see
    all your successes, but it's not good if they obscure failures.  Second,
    when an assertion fails, it raises an exception, which ends our
    program:</p>

<!--[[[cog include_file("porttest3_broken.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python porttest3_broken.py
  File "porttest3_broken.py", line 5
    print "Empty portfolio cost: %s, should be 0.0" % p.cost()
                                                  ^
SyntaxError: invalid syntax
</code>
<!--[[[end]]] }}}-->

    <p>We can only see a single failure, then the rest of the program is
    skipped, and we don't know the results of the rest of the tests.  This
    limits the amount of information our tests can give us.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Getting complicated!</h1>
    <ul>
        <li>Tests will grow</li>
        <li>Real programs</li>
        <li>Real engineering</li>
        <li>Handle common issues in standard ways</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>As you can see, we're starting to build up a real program here. To make
    the output hide successes, and continue on in the face of failures, you'll
    have to create a way to divide this test file into chunks, and run the
    chunks so that if one fails, others will still run.  It starts to get
    complicated.</p>

    <p>Anyone writing tests will face these problems, and common problems can
    often be solved with standard libraries. In the next section, we'll use
    unittest, from the Python standard library, to solve our common
    problems.</p>

</div><!-- }}} -->

<div class="hidden_slide">
    <h1>Good tests</h1>
    <ul>
        <li>Automated</li>
        <li>Fast</li>
        <li>Reliable</li>
        <li>Informative</li>
        <li>Focused</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Before we look at unittest, let's talk for a minute about what qualities
    make for good tests.</p>

    <p>The whole point of a test is to tell you something about your code: does
    it work?  They are no use to us if they are a burden to run, so we need
    them to be automated, and they need to be fast.</p>

    <p>Tests have to be reliable so that we can use them to guide us.  If tests
    are flaky, or we don't believe their results, then they could give us false
    results.  That would lead us on wild goose chases.  The world is chaotic
    enough, we don't want to add to it by writing tests that pose more
    questions than they answer.  To be reliable, tests must be repeatable, and
    they must be authoritative.  We have to believe what they tell us.</p>

    <p>What they tell us must be informative. Think about your workflow when
    running tests: if the test pass, you go on to write more features, or you
    go outside and enjoy the sunshine.  But what happens when they fail?  Then
    you have to find out what is wrong with your product code so you can fix
    it.  The more the test can tell you about the failure, the more useful they
    are to you.  So we want our tests to be informative.</p>

    <p>We also want them to be focused: the less code tested by each test,
    the more that test tells us when it fails. The broken code must be in the
    code run by the test.  The smaller that chunk of product code, the more
    you've already narrowed down the cause of the failure.  So we want each
    test to test as little code as possible.</p>

    <p>This may seem surprising, often we're looking for code we write to do
    as big a job as possible.  In this case, we want each test to do as little
    as possible, because then when it fails, it will focus us in on a small
    section of product code to fix.</p>

    <!--
    Think of it like this: if broken product code is
    a crime, then the line containing the bug is the perpetrator, and your test
    should narrow down the list of suspects as much as possible.  Don't think
    of your test as testing as little as possible, think of it as exonerating
    as much of your code as possible.
    -->

</div><!-- }}} -->

<!-- }}} -->
<!-- *** Using py.test {{{ -->

<div class="slide section" data-layout="clean">
    <h1>unittest and py.test</h1>
    <h2>Writing tests</h2>
</div>

<div class="slide">
    <h1>unittest</h1>
    <ul>
        <li>In the standard library</li>
        <li>Based on test classes</li>
        <li>Patterned on xUnit</li>
        <li>Wordy, "not Pythonic"</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>The Python standard library provides the unittest module.  It gives
    us the infrastructure for writing well-structured tests.</p>

    <p>The design of unittest is modelled on the common xUnit pattern that is
    available in many different languages, notably jUnit for Java.  This gives
    unittest a more verbose feeling than many Python libraries.  Some people
    don't like this and prefer other styles of tests, but unittest is by far
    the most widely used library, and is well-supported by every test tool.</p>

    <p>There are alternatives to unittest, but it's a good foundation to build
    on.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>py.test</h1>
    <ul>
        <li>Third-party test runner</li>
        <li>Functions instead of classes</li>
        <li>Can be quirky</li>
        <li>Also runs unittest tests</li>
    </ul>
</div>


<div class="slide">
    <h1>Project structure</h1>
    <div class="code">
        <div class='line'>├── my_awesome_product</div>
        <div class='line'>│   ├── __init__.py</div>
        <div class='line'>│   ├── a_thing.py</div>
        <div class='line'>│   ├── another_thing.py</div>
        <div class='line'>│   ├── more_things.py</div>
        <div class='line'>│   └── other_things.py</div>
        <div class='line'>├── README.rst</div>
        <div class='line'>├── setup.py</div>
        <div class='line'>├── tests</div>
        <div class='line'>│   ├── __init__.py                  <span class='c'># maybe...</span></div>
        <div class='line'>│   ├── test_a_thing.py</div>
        <div class='line'>│   ├── test_another_thing.py</div>
        <div class='line'>│   ├── test_more_things.py</div>
        <div class='line'>│   └── test_other_things.py</div>
    </div>
    <ul>
        <li>Separate "tests" directory</li>
        <li>Files named "test_*.py"</li>
    </ul>
</div>


<div class="slide">
    <h1>Running tests</h1>
    <ul>
        <li>Test runners can find your tests</li>
    </ul>
    <!--[[[cog
    include_code("""\
        $ py.test                           # .. for pytest


        $ python -m unittest discover       # .. for unittest


        $ nosetests                         # .. for nose
    """, lang="console")
    ]]]-->
    <pre class='console'>
    $ py.test                           # .. for pytest


    $ python -m unittest discover       # .. for unittest


    $ nosetests                         # .. for nose
    </pre>
    <!--[[[end]]]-->
</div>


<div class="slide">
    <h1>A simple unit test</h1>
    <!--[[[cog include_file("test_port1_pytest.py")   ]]] {{{ -->
    <pre class='python'>
    # test_port1_pytest.py

    from portfolio1 import Portfolio

    def test_buy_one_stock():
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        assert p.cost() == 17648.0
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port1_pytest.out")   ]]] {{{ -->
    <pre class='text'>
    $ py.test -q test_port1_pytest.py
    .                                                              [100%]
    1 passed in 0.04 seconds
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li>Every "test_*" function is a test</li>
    </ul>
</div>

<div class="slide">
    <h1>Under the covers</h1>
    <!--[[[cog
    include_code("""\
        # py.test runs the tests as if I had written:
        try:
            test_buy_one_stock()
        except:
            [record failure]
        else:
            [record success]
    """, lang="python")
    ]]]-->
    <pre class='python'>
    # py.test runs the tests as if I had written:
    try:
        test_buy_one_stock()
    except:
        [record failure]
    else:
        [record success]
    </pre>
    <!--[[[end]]]-->
</div>

<div class="slide" data-layout="clean">
    <h1>Add more tests</h1>
    <!--[[[cog include_file("test_port2_pytest.py", start=5)   ]]] {{{ -->
    <pre class='python'>
    def test_empty():
        p = Portfolio()
        assert p.cost() == 0.0

    def test_buy_one_stock():
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        assert p.cost() == 17648.0

    def test_buy_two_stocks():
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        p.buy("HPQ", 100, 36.15)
        assert p.cost() == 21263.0
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port2_pytest.out", highlight=[2])   ]]] {{{ -->
    <pre class='text'>
    $ py.test -q test_port2_pytest.py
    ...                                                            [100%]
    3 passed in 0.03 seconds
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li>A dot for every passed test</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>One test isn't enough, let's add some more.  Here we add a simpler test,
    test_empty, and a more complicated test, test_buy_two_stocks.  Each test is
    another test method in our PortfolioTest class:</p>

<!--[[[cog include_file("test_port2.py", px=True) ]]] {{{ -->
<code lang='python'>
# test_port2.py

import unittest
from portfolio1 import Portfolio

class PortfolioTest(unittest.TestCase):
    def test_empty(self):
        p = Portfolio()
        assert p.cost() == 0.0

    def test_buy_one_stock(self):
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        assert p.cost() == 17648.0

    def test_buy_two_stocks(self):
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        p.buy("HPQ", 100, 36.15)
        assert p.cost() == 21263.0
</code>
<!--[[[end]]] }}}-->

    <p>Each one creates the portfolio object it needs, performs the
    manipulations it wants, and makes assertions about the outcome.</p>

    <p>When you run the tests, it prints a dot for every test that passes,
    which is why you see "..." in the test output here:</p>

<!--[[[cog include_file("test_port2.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port2
...
------------------------------------------------------------
Ran 3 tests in 0.000s

OK
</code>
<!--[[[end]]] }}}-->

</div><!-- }}} -->

<div class="slide" data-layout="clean">
    <h1>Under the covers</h1>
    <!--[[[cog
    include_code("""\
        # py.test runs the tests as if I had written:
        try:
            test_empty()
        except:
            [record failure]
        else:
            [record success]

        try:
            test_buy_one_stock()
        except:
            [record failure]
        else:
            [record success]

        try:
            test_buy_two_stocks()
        except:
            [record failure]
        else:
            [record success]
    """, lang="python", highlight=[3, 10, 17])
    ]]]-->
    <pre class='python'>
    # py.test runs the tests as if I had written:
    try:
        test_empty()
    except:
        [record failure]
    else:
        [record success]

    try:
        test_buy_one_stock()
    except:
        [record failure]
    else:
        [record success]

    try:
        test_buy_two_stocks()
    except:
        [record failure]
    else:
        [record success]
    </pre>
    <!--[[[end]]]-->
</div>

<div class="text"><!-- {{{ -->
    <p>With three tests, the execution model is much as before.  The key
    thing to note here is that a new instance of PortfolioTest is created
    for each test method.  This helps to guarantee an important property of
    good tests: isolation.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Test isolation</h1>
    <ul>
        <li>Tests don't affect each other</li>
        <li>Failure doesn't stop next tests</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Test isolation means that each of your tests is unaffected by every
    other test. This is good because it makes your tests more repeatable, and
    they are clearer about what they are testing. It also means that if a
    test fails, you don't have to think about all the conditions and data
    created by earlier tests: running just that one test will reproduce the
    failure.</p>

    <p>Earlier we had a problem where one test failing prevented the other
    tests from running.  Here unittest is running each test independently, so
    if one fails, the rest will run, and will run just as if the earlier test
    had succeeded.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>What failure looks like</h1>
    <!--[[[cog include_file("test_port2_pytest_broken.out", highlight=[2, 9, 10])   ]]] {{{ -->
    <pre class='text'>
    $ py.test -q test_port2_pytest_broken.py
    .F.                                                            [100%]
    ============================== FAILURES ==============================
    _________________________ test_buy_one_stock _________________________

        def test_buy_one_stock():
            p = Portfolio()
            p.buy("IBM", 100, 176)      # this is wrong, to make the test fail!
    &gt;       assert p.cost() == 17648.0
    E       assert 17600.0 == 17648.0
    E        +  where 17600.0 = &lt;bound method Portfolio.cost of &lt;portfolio1.Portfolio object at 0x105836048&gt;&gt;()
    E        +    where &lt;bound method Portfolio.cost of &lt;portfolio1.Portfolio object at 0x105836048&gt;&gt; = &lt;portfolio1.Portfolio object at 0x105836048&gt;.cost

    test_port2_pytest_broken.py:12: AssertionError
    1 failed, 2 passed in 0.08 seconds
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="good">Good: failed test didn't stop others</li>
        <li class="good">Good: shows the value returned</li>
        <li class="unsure">Wow: automatic display of values</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>So far, all of our tests have passed.  What happens when they fail?</p>

<!--[[[cog include_file("test_port2_broken.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port2_broken
F..
============================================================
FAIL: test_buy_one_stock (test_port2_broken.PortfolioTest)
------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/ned/prz/test0/test_port2_broken.py", line 14, in test_buy_one_stock
    assert p.cost() == 17648.0
AssertionError

------------------------------------------------------------
Ran 3 tests in 0.001s

FAILED (failures=1)
</code>
<!--[[[end]]] }}}-->

    <p>The test runner prints a dot for every test that passes, and it prints
    an "F" for each test failure, so here we see ".F." in the output.  Then
    for each test failure, it prints the name of the test, and the traceback
    of the assertion failure.</p>

    <p>This style of test output means that test successes are very quiet, just
    a single dot.  When a test fails, it stands out, and you can focus on them.
    Remember: when your tests pass, you don't have to do anything, you can go
    on with other work, so passing tests, while a good thing, should not cause
    a lot of noise.  It's the failing tests we need to think about.</p>

    <p>It's great that the traceback shows what assertion failed, but notice
    that it doesn't tell us what bad value was returned.  We can see that we
    expected it to be 17648.0, but we don't know what the actual value was.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Testing for exceptions</h1>
    <ul>
        <li>Can't just call the function</li>
    </ul>
    <!--[[[cog include_file("test_port4_pytest_broken.py", start=20)   ]]] {{{ -->
    <pre class='python'>
    def test_bad_input():
        p = Portfolio()
        p.buy("IBM")
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port4_pytest_broken.out", highlight=[9])   ]]] {{{ -->
    <pre class='text'>
    $ py.test -q test_port4_pytest_broken.py
    ...F                                                           [100%]
    ============================== FAILURES ==============================
    ___________________________ test_bad_input ___________________________

        def test_bad_input():
            p = Portfolio()
    &gt;       p.buy("IBM")
    E       TypeError: buy() missing 2 required positional arguments: 'shares' and 'price'

    test_port4_pytest_broken.py:22: TypeError
    1 failed, 3 passed in 0.07 seconds
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>Here we try to write an automated test of an error case: calling a
    method with too few arguments:</p>

<!--[[[cog include_file("test_port4_broken.py", start=22, end=24, px=True) ]]] {{{ -->
<code lang='python'>
def test_bad_input(self):
    p = Portfolio()
    p.buy("IBM")
</code>
<!--[[[end]]] }}}-->

    <p>This test won't do what we want.  When we call buy() with too few
    arguments, of course it raises TypeError, and there's nothing to catch the
    exception, so the test ends with an Error status:</p>

<!--[[[cog include_file("test_port4_broken.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port4_broken
E...
============================================================
ERROR: test_bad_input (test_port4_broken.PortfolioTest)
------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/ned/prz/test0/test_port4_broken.py", line 24, in test_bad_input
    p.buy("IBM")
TypeError: buy() missing 2 required positional arguments: 'shares' and 'price'

------------------------------------------------------------
Ran 4 tests in 0.000s

FAILED (errors=1)
</code>
<!--[[[end]]] }}}-->

    <p>That's not good, we want all our tests to pass.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>pytest.raises</h1>
    <!--[[[cog include_file("test_port4_pytest.py", start=22, end=26)   ]]] {{{ -->
    <pre class='python'>
    def test_bad_input():
        p = Portfolio()
        with pytest.raises(TypeError):
            p.buy("IBM")
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port4_pytest.out")   ]]] {{{ -->
    <pre class='text'>
    $ py.test -q test_port4_pytest.py
    ....                                                           [100%]
    4 passed in 0.03 seconds
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>To properly handle the error-raising function call, we use a method
    called assertRaises:</p>

<!--[[[cog include_file("test_port4.py", start=22, end=25, px=True) ]]] {{{ -->
<code lang='python'>
def test_bad_input(self):
    p = Portfolio()
    with self.assertRaises(TypeError):
        p.buy("IBM")
</code>
<!--[[[end]]] }}}-->

    <p>This neatly captures our intent: we are asserting that a statement will
    raise an exception.  It's used as a context manager with a "with" statement
    so that it can handle the exception when it is raised:</p>

<!--[[[cog include_file("test_port4.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port4
....
------------------------------------------------------------
Ran 4 tests in 0.000s

OK
</code>
<!--[[[end]]] }}}-->

    <p>Now our test passes because the TypeError is caught by the assertRaises
    context manager.  The assertion passes because the exception raised is the
    same type we claimed it would be, and all is well.</p>

    <p>If you have experience with unittest before 2.7, the context manager
    style is new, and much more convenient than the old way.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>More code:&#xa0; sell()</h1>
    <!--[[[cog include_file("portfolio2.py", start=21, end=30)   ]]] {{{ -->
    <pre class='python'>
    def sell(self, name, shares):
        """Sell some shares."""
        for holding in self.stocks:
            if holding[0] == name:
                if holding[1] &lt; shares:
                    raise ValueError("Not enough shares")
                holding[1] -= shares
                break
        else:
            raise ValueError("You don't own that stock")
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>Our testing is going well, time to extend our product.  Let's add
    a .sell() method to our Portfolio class.  It will remove shares of a
    particular stock from our Portfolio:</p>

<!--[[[cog include_file("portfolio2.py", start=21, end=30, px=True) ]]] {{{ -->
<code lang='python'>
def sell(self, name, shares):
    """Sell some shares."""
    for holding in self.stocks:
        if holding[0] == name:
            if holding[1] &lt; shares:
                raise ValueError("Not enough shares")
            holding[1] -= shares
            break
    else:
        raise ValueError("You don't own that stock")
</code>
<!--[[[end]]] }}}-->

    <p>Note: this code is very simple, for the purpose of fitting on a slide!</p>

</div><!-- }}} -->

<div class="slide" data-layout="clean">
    <h1>Testing sell()</h1>
    <!--[[[cog include_file("test_port5_pytest.py", start=32)   ]]] {{{ -->
    <pre class='python'>
    def test_sell():
        p = Portfolio()
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        p.sell("MSFT", 50)
        assert_cost_equal(p, 6450)

    def test_not_enough():
        p = Portfolio()                 # Didn't I just do this?
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        with pytest.raises(ValueError):
            p.sell("MSFT", 200)

    def test_dont_own_it():
        p = Portfolio()                 # What, again!?!?
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        with pytest.raises(ValueError):
            p.sell("IBM", 1)
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>To test the .sell() method, we add three more tests.  In each case,
    we need to create a portfolio with some stocks in it so that we have
    something to sell:</p>

<!--[[[cog include_file("test_port5.py", start=36, px=True) ]]] {{{ -->
<code lang='python'>
class PortfolioSellTest(PortfolioTestCase):
    def test_sell(self):
        p = Portfolio()
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        p.sell("MSFT", 50)
        self.assertCostEqual(p, 6450)

    def test_not_enough(self):
        p = Portfolio()             # Didn't I just do this?
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        with self.assertRaises(ValueError):
            p.sell("MSFT", 200)

    def test_dont_own_it(self):
        p = Portfolio()             # What, again!?!?
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        with self.assertRaises(ValueError):
            p.sell("IBM", 1)
</code>
<!--[[[end]]] }}}-->

    <p>But now our tests are getting really repetitve.  We've used the same
    four lines of code to create the same portfolio object three times.</p>

</div><!-- }}} -->


<div class="slide">
    <h1>Setting up a test</h1>
    <!--[[[cog include_file("test_port6_pytest.py", start=33)   ]]] {{{ -->
    <pre class='python'>
    @pytest.fixture()
    def simple_portfolio():
        p = Portfolio()
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        return p

    def test_sell(simple_portfolio):
        simple_portfolio.sell("MSFT", 50)
        assert_cost_equal(simple_portfolio, 6450)

    def test_not_enough(simple_portfolio):
        with pytest.raises(ValueError):
            simple_portfolio.sell("MSFT", 200)

    def test_dont_own_it(simple_portfolio):
        with pytest.raises(ValueError):
            simple_portfolio.sell("IBM", 1)
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="unsure">Fixture called based on argument name</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>This is a common problem, so unittest has a solution for us.  A test
    class can define a .setUp() method.  This method is invoked before each
    test method.  Because your test class is a class, you have a self object
    that you can create attributes on:</p>

<!--[[[cog include_file("test_port6.py", start=36, px=True) ]]] {{{ -->
<code lang='python'>
class PortfolioSellTest(PortfolioTestCase):
    # Invoked before each test method
    def setUp(self):
        self.p = Portfolio()
        self.p.buy("MSFT", 100, 27.0)
        self.p.buy("DELL", 100, 17.0)
        self.p.buy("ORCL", 100, 34.0)

    def test_sell(self):
        self.p.sell("MSFT", 50)
        self.assertCostEqual(self.p, 6450)

    def test_not_enough(self):
        with self.assertRaises(ValueError):
            self.p.sell("MSFT", 200)

    def test_dont_own_it(self):
        with self.assertRaises(ValueError):
            self.p.sell("IBM", 1)
</code>
<!--[[[end]]] }}}-->

    <p>Here we have a .setup() method that creates a portfolio and stores it as
    self.p.  Then the three test methods can simply use the self.p portfolio.
    Note the three test methods are much smaller, since they share the common
    setup code in .setUp().</p>

    <p>Naturally, there's also a .tearDown() method that will be invoked when
    the test method is finished.  tearDown can clean up after a test, for
    example if your setUp created records in a database, or files on disk.  We
    don't need one here.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Under the covers</h1>
    <!--[[[cog
    include_code("""\
        [ introspection of argument names ]
        try:
            # Call the fixtures
            simple_portfolio_value = simple_portfolio()
        except:
            [record error]
        else:
            try:
                # Call the test method
                test_sell(simple_portfolio_value)
            except:
                [record failure]
            else:
                [record success]
    """, lang="python", highlight=[4, 10])
    ]]]-->
    <pre class='python'>
    [ introspection of argument names ]
    try:
        # Call the fixtures
        simple_portfolio_value = simple_portfolio()
    except:
        [record error]
    else:
        try:
            # Call the test method
            test_sell(simple_portfolio_value)
        except:
            [record failure]
        else:
            [record success]
    </pre>
    <!--[[[end]]]-->
</div>

<div class="text"><!-- {{{ -->

    <p>Here's the detail on how unittest runs the setUp, test_method, and
    tearDown methods.  A test case object is instantiated, and its .setUp() is
    run.  if it doesn't raise an exception, then the .test_method() is run,
    noting its outcome.  No matter what happens with the .test_method(), the
    tearDown() is run.</p>

    <p>This is an important reason to put clean up code in a tearDown() method:
    it will be run even if your test fails.  If you try to clean up after
    yourself at the end of your test method, then if the test fails, the
    clean up doesn't happen, and you may pollute other tests.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Fixtures</h1>
    <ul>
        <li>Establish context</li>
        <li>Common pre- or post- work</li>
        <li>Isolation, even with failures</li>
        <li>unittest: setUp and addCleanup</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>setUp and tearDown are important ways to write more concise tests, and
    more importantly, give you powerful tools for ensuring proper test
    isolation.</p>

    <p>If you find your setUp and tearDown methods getting elaborate, there are
    third party "fixture" libraries that can help automate the creation of
    test data and environments.</p>

</div><!-- }}} -->

<div class="hidden_slide">
    <h1>How NOT to do it</h1>
    <!--[[[cog
    include_code("""\
        class MyBadTestCase(unittest.TestCase):
            def test_a_thing(self):
                old_global = SOME_GLOBAL_THING
                SOME_GLOBAL_THING = new_test_value

                do_my_test_stuff()

                SOME_GLOBAL_THING = old_global
    """, lang="python")
    ]]]-->
    <pre class='python'>
    class MyBadTestCase(unittest.TestCase):
        def test_a_thing(self):
            old_global = SOME_GLOBAL_THING
            SOME_GLOBAL_THING = new_test_value

            do_my_test_stuff()

            SOME_GLOBAL_THING = old_global
    </pre>
    <!--[[[end]]]-->
    <ul>
        <li>Common impulse</li>
        <li>But if test fails, globals aren't restored</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>The right way</h1>
    <!--[[[cog
    include_code("""\
        class MyGoodTestCase(unittest.TestCase):
            def setUp(self):
                self.old_global = SOME_GLOBAL_THING
                SOME_GLOBAL_THING = new_test_value

            def tearDown(self):
                SOME_GLOBAL_THING = self.old_global

            def test_a_thing(self):
                do_my_test_stuff()
    """, lang="python")
    ]]]-->
    <pre class='python'>
    class MyGoodTestCase(unittest.TestCase):
        def setUp(self):
            self.old_global = SOME_GLOBAL_THING
            SOME_GLOBAL_THING = new_test_value

        def tearDown(self):
            SOME_GLOBAL_THING = self.old_global

        def test_a_thing(self):
            do_my_test_stuff()
    </pre>
    <!--[[[end]]]-->
    <ul>
        <li>tearDown gets run no matter what *</li>
        <li>Reuse: same setUp and tearDown apply to all the test methods</li>
        <li>Test method is small and focused</li>
        <li>* unless setUp fails</li>
    </ul>
</div>

<div class="slide">
    <h1>Tests are real code!</h1>
    <ul>
        <li>Helper functions, classes, etc.</li>
        <li>Can become significant</li>
        <li>Might need tests!</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>You can see as we add more capability to our tests, they are becoming
    significant, even with the help of unittest.  This is a key point to
    understand: writing tests is real engineering!</p>

    <p>If you approach your tests as boring paperwork to get done because
    everyone says you have to, you will be unhappy and you will have bad
    tests.</p>

    <p>You have to approach tests as valuable solutions to a real problem: how
    do you know if your code works?  And as a valuable solution, you will put
    real effort into it, designing a strategy, building helpers, and so on.</p>

    <p>In a well-tested project, it isn't unusual to have more lines of tests
    than you have lines of product code! It is definitely worthwhile to
    engineer those tests well.</p>

</div><!-- }}} -->

<!-- }}} -->

<!-- *** Approaches {{{ -->
<div class="hidden_slide section todo" data-layout="clean">
    <h1>Approaches</h1>
    <h2>crafting tests</h2>
</div>

<div class="hidden_slide">
    <h1>What to test?</h1>
    <ul>
        <li>Any code that you want to work</li>
        <li>Start with what worries you</li>
        <li>Where are your bugs?</li>
    </ul>
</div>

<!--

- White box testing
- Black box testing
- Regression testing

- non-functional testing
    - performance
    - security
    - usability

-->

<div class="hidden_slide">
    <h1>How to start?</h1>
    <ul>
        <li>Pick a chunk of code</li>
        <li>What should it do?</li>
        <li>Test that</li>
        <li>What shouldn't it do?</li>
        <li>Test that</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Test granularity</h1>
    <ul>
        <li>How big is the code chunk?</li>
        <li>Creates a hierarchy of tests:
            <ul>
                <li>Unit</li>
                <li>Functional</li>
                <li>Integration</li>
                <li>System</li>
            </ul></li>
        <li>Start small</li>
    </ul>
</div>


<div class="hidden_slide">
    <h1>What should the code do?</h1>
    <ul>
        <li>This can be difficult!</li>
        <li>Tests force you to decide</li>
        <li>Be as clear as you can</li>
        <li>(Document it in your docstrings)</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Test what the code should do</h1>
    <ul>
        <li>Typical values</li>
        <li>Edge values</li>
        <li>Combinations of values</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Test what the code shouldn't do</h1>
    <ul>
        <li>Error conditions</li>
        <li>Absurd values</li>
        <li>Common mistakes in usage</li>
        <li>Does it fail the way it should?</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Where to put them?</h1>
    <ul>
        <li>Put tests in their own files</li>
        <li>Name them test_*.py</li>
        <li>Parallel to the code they're testing</li>
        <li>Pick your granularity</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Good tests should be...</h1>
    <ul>
        <li>Automated</li>
        <li>Repeatable</li>
        <li>Convenient: fast</li>
        <li>Unambiguous</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>How much is enough?</h1>
    <ul>
        <li>Hard to know</li>
        <li>Depends on your needs</li>
        <li>Coverage measurement can help</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Tests will fail</h1>
    <ul>
        <li>Could be the code is broken</li>
        <li>Could also be the tests are broken</li>
        <li>Tests have to be maintained</li>
        <li>Refactoring code might mean refactoring tests too</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Test-Driven Development</h1>
    <ul>
        <li>Write tests before code!</li>
        <li>Ensures code is testable</li>
        <li>Produces better code</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Testability</h1>
    <ul>
        <li>The quality of being testable</li>
        <li>Affects the design of your code</li>
        <li>Mostly: improved modularity</li>
        <li>See my PyCon 2010 talk: <a href='http://pycon.blip.tv/file/3261272'>Tests &amp; Testability</a></li>
    </ul>
</div>

<!-- }}} -->

<!-- *** nose {{{ -->
<div class="hidden_slide section" data-layout="clean">
    <h1>nose and py.test</h1>
    <h2>Running tests</h2>
</div>

<div class="hidden_slide">
    <h1>Test runners</h1>
    <ul>
        <li>Third-party test runners: nose, py.test, trial</li>
        <li>Know how to run your unittest tests</li>
        <li>Test discovery</li>
        <li>Run tests better</li>
        <li>Plugins provide lots of features</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Test discovery</h1>
    <ul>
        <li>Running one file of tests is easy</li>
        <li>Pre-2.7 unittest: hard to run many test files</li>
        <li>New test runners provide test discovery</li>
        <li>They sniff out your tests wherever they are</li>
    </ul>
</div>

<!-- }}} -->

<!-- *** Other test runners {{{ -->
<div class="hidden_slide">
    <h1>Running tests</h1>
    <ul>
        <li>Show test names as they run</li>
        <li>Capture stdout</li>
        <li>Stop on first failure</li>
        <li>These are also in 2.7 unittest</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Plugins</h1>
    <ul>
        <li>LOTS of useful functions added by plugins</li>
        <li>parallel execution</li>
        <li>attribute-based test selection</li>
        <li>output formats: color, subunit, xml, etc</li>
        <li>extreme isolation</li>
        <li>django integration</li>
        <li>etc</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Class-less tests</h1>
    <ul>
        <li>*Unit patterns are based on Smalltalk</li>
        <li>But Python can have code outside of classes</li>
        <li>So why do my tests have to be in classes?</li>
        <li>Test can be just functions</li>
        <li>And why can't my asserts be plain asserts?</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Test generators</h1>
    <ul>
        <li>Tests can be created with a generator</li>
        <li>Generator yields callable + args</li>
        <li>Each yield is a separate test</li>
        <li>This produces four tests, two pass:</li>
    </ul>
    <pre class='brush: python'>
    def test_evens():
        for i in range(4):
            yield check_even, i

    def check_even(n):
        assert n % 2 == 0
    </pre>
    <pre class='brush: python'>
    def test_0():
        check_even(0)
    def test_1():
        check_even(1)
    def test_2():
        check_even(2)
    def test_3():
        check_even(3)
    </pre>
</div>

<div class="hidden_slide">
    <h1>nose and unittest together</h1>
    <ul>
        <li>nose extended unittest</li>
        <li>Then unittest grew in 2.7</li>
        <li>They don't always get along</li>
        <li>Be careful</li>
    </ul>
</div>

<div class="hidden_slide highlight_code_red">
    <h1>py.test</h1>
    <pre class='brush: plain, highlight: [17,18,19]'>
    $ py.test test_port2_broken.py
    =========================== test session starts ===========================
    platform win32 - - Python 2.7.2 - - pytest-2.1.0
    collected 3 items

    test_port2_broken.py .F.

    ================================ FAILURES =================================
    _________________________ PortfolioTest.test_ibm __________________________

    self = &lt;test_port2_broken.PortfolioTest testMethod=test_ibm>

        def test_ibm(self):
            p = Portfolio()
            p.buy("IBM", 100, 176)
    &gt;       assert p.cost() == 17648.0
    E       AssertionError: assert 17600.0 == 17648.0
    E        +  where 17600.0 = &lt;bound method Portfolio.cost of &lt;portfolio1.Por
    E        +    where &lt;bound method Portfolio.cost of &lt;portfolio1.Portfolio o

    test_port2_broken.py:14: AssertionError
    =================== 1 failed, 2 passed in 0.12 seconds ====================
    </pre>
</div>

<div class="hidden_slide">
    <h1>Twisted's trial</h1>
    <ul>
        <li>Many advanced options</li>
        <li>Some particular to Twisted</li>
        <li>Control GC between tests</li>
        <li>Check global state</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>IDEs</h1>
    <ul>
        <li>IDEs like Eclipse and Netbeans also have test runners</li>
        <li>Vim and Emacs too</li>
        <li>I know nothing about them</li>
        <li>They are probably awesome</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Test runners</h1>
    <ul>
        <li>unittest (2.7)</li>
        <li>nose, py.test, trial</li>
        <li>IDEs, Vim, Emacs</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Lots of options</h1>
    <ul>
        <li>However you want to run your tests, you can</li>
        <li>Choose the runner that suits you</li>
        <li>Plugins allow further customization</li>
    </ul>
</div>

<!-- }}} -->

<!-- *** Coverage {{{ -->
<div class="hidden_slide section" data-layout="clean">
    <h1>Coverage</h1>
    <h2>Testing tests</h2>
</div>

<div class="hidden_slide">
    <h1>What code are you testing?</h1>
    <ul>
        <li>The goal: tests execute product code</li>
        <li>But do they really?</li>
        <li>How much of it?</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>Coverage measurement</h1>
    <ul>
        <li>Run your tests</li>
        <li>Track what parts of product code are executed</li>
        <li>Report on covered / not covered</li>
        <li>You find code not being tested</li>
        <li>Write more tests</li>
        <li>The world is better!</li>
    </ul>
</div>

<!--
<div class="hidden_slide">
    <h1>Running coverage.py</h1>
    <ul>
        <li>Install it from PyPI</li>
        <li><tt>coverage run my_prog.py arg ...</tt></li>
        <li><tt>coverage html</tt></li>
        <li>Or: &nbsp;<tt>nosetests - -with-cover ...</tt></li>
        <li>Or: &nbsp;<tt>py.test - -cov ...</tt></li>
    </ul>
</div>
-->

<!--
<div class="hidden_slide">
    <h1>HTML report</h1>
    <iframe src='test0_static/htmlcov/index.html' style='background:white;width:100%;height:85%;'></iframe>
</div>
-->

<div class="hidden_slide">
    <h1>Coverage can only tell you a few things</h1>
    <ul>
        <li>What lines were executed</li>
        <li>What branches were taken</li>
        <li>100% coverage is difficult to reach</li>
        <li>100% coverage doesn't tell you everything</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>What coverage can't tell you</h1>
    <ul>
        <li>Are you exercising all your data?</li>
        <li>Are you exercising all your HTML templates?</li>
        <li>Are you checking results properly?</li>
        <li>Are you hitting all edge conditions?</li>
        <li>Are you testing the right things?</li>
        <li>Are you building the right product?  ;-)</li>
    </ul>
</div>


<!-- }}} -->

<!-- *** Mocking {{{ -->
<div class="slide section" data-layout="clean">
    <h1>Mocks</h1>
    <h2>Focusing tests</h2>
</div>

<div class="text"><!-- {{{ -->

    <p>We've covered the basics of how to write tests.  There's more to it,
    but I want to skip ahead to a more advanced technique: mocking.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Testing small amounts of code</h1>
    <ul>
        <li>Systems are built in layers</li>
        <li>Components depend on each other</li>
        <li>How to test just one component?</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Any real-sized program is built in layers and components.  In the full
    system, each component uses a number of other components.  As we've
    discussed, the best tests focus on just one piece of code.  How can you
    test a component in isolation from all of the components it depends on?</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Dependencies are bad</h1>
    <ul>
        <li>More suspect code in each test</li>
        <li>Slow components</li>
        <li>Unpredictable components</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Dependencies among components are bad for testing.  They mean that when
    you are testing one component, you are actually testing it and all the
    components it depends on.  This is more code than you want to be thinking
    about when writing or debugging a test.</p>

    <p>Also, some components might be slow, which will make your tests slow,
    which makes it hard to write lots of tests that will be run frequently.</p>

    <p>Lastly, some components are unpredictable, which makes it hard to write
    repeatable tests.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Test Doubles</h1>
    <ul>
        <li>Replace a component's dependencies</li>
        <li>Focus on one component</li>
    </ul>
    <img src='mock.png'/>
</div>

<div class="text"><!-- {{{ -->

    <p>The solutions to these problems are known as test doubles: code that
    can stand in for real code during testing, kind of like stunt doubles in
    movies.</p>

    <p>The idea is to replace certain dependencies with doubles. During
    testing, you test the primary component, and avoid invoking the complex,
    time-consuming, or unpredictable dependencies, because they have been
    replaced.</p>

    <p>The result is tests that focus in on the primary component without
    involving complicating dependencies.</p>

</div><!-- }}} -->

<div class="slide" data-layout="clean">
    <h1>Portfolio: Real-time data!</h1>
    <!--[[[cog include_file("portfolio3.py", section="value")   ]]] {{{ -->
    <pre class='python'>
    def current_prices(self):
        """Return a dict mapping names to current prices."""
        url = "http://finance.yahoo.com/d/quotes.csv?f=sl1&amp;s="
        url += ",".join(sorted(s[0] for s in self.stocks))
        data = urllib.urlopen(url)
        return { sym: float(last) for sym, last in csv.reader(data) }

    def value(self):
        """Return the current value of the portfolio."""
        prices = self.current_prices()
        total = 0.0
        for name, shares, _ in self.stocks:
            total += shares * prices[name]
        return total
    </pre>
    <!--[[[end]]] }}}-->
    <!-- ** Interactive session {{{ -->
    <!--[[[cog
    prompt_session("""\
        p = Portfolio()
        p.buy("IBM", 100, 150.0)
        p.buy("HPQ", 100, 30.0)

        p.current_prices()

        p.value()
        """,
        prelude="""\
        from portfolio3 import Portfolio
        """)
    ]]]-->
    <pre class='python console'>
    &gt;&gt;&gt; p = Portfolio()
    &gt;&gt;&gt; p.buy("IBM", 100, 150.0)
    &gt;&gt;&gt; p.buy("HPQ", 100, 30.0)

    &gt;&gt;&gt; p.current_prices()
    Traceback (most recent call last):
      File "&lt;console&gt;", line 1, in &lt;module&gt;
      File "/Users/ned/prz/test0/portfolio3.py", line 55, in current_prices
        data = urllib.urlopen(url)
    AttributeError: module 'urllib' has no attribute 'urlopen'

    &gt;&gt;&gt; p.value()
    Traceback (most recent call last):
      File "&lt;console&gt;", line 1, in &lt;module&gt;
      File "/Users/ned/prz/test0/portfolio3.py", line 60, in value
        prices = self.current_prices()
      File "/Users/ned/prz/test0/portfolio3.py", line 55, in current_prices
        data = urllib.urlopen(url)
    AttributeError: module 'urllib' has no attribute 'urlopen'
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>As an example, we'll add more code to our Portfolio class.  This code
    will tell us the actual real-world current value of our collection of
    stocks.  To do that, we've added a method called current_prices which
    uses a Yahoo web service to get the current market prices of the stocks
    we hold:</p>

<!--[[[cog include_file("portfolio3.py", section="value", px=True) ]]] {{{ -->
<code lang='python'>
def current_prices(self):
    """Return a dict mapping names to current prices."""
    url = "http://finance.yahoo.com/d/quotes.csv?f=sl1&amp;s="
    url += ",".join(sorted(s[0] for s in self.stocks))
    data = urllib.urlopen(url)
    return { sym: float(last) for sym, last in csv.reader(data) }

def value(self):
    """Return the current value of the portfolio."""
    prices = self.current_prices()
    total = 0.0
    for name, shares, _ in self.stocks:
        total += shares * prices[name]
    return total
</code>
<!--[[[end]]] }}}-->

    <p>The new .value() method will get the current prices, and sum up the
    value of each stock holding to tell us the current value.</p>

    <p>Here we can try out our code manually, and see that current_prices()
    really does return us a dictionary of market prices, and .value() computes
    the value of the portfolio using those market prices.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>But how to test it?</h1>
    <ul>
        <li>Live data: unpredictable</li>
        <li>Slow?</li>
        <li>Unavailable?</li>
        <li>Question should be:
            <ul>
                <li>"Assuming yahoo.com is working,</li>
                <li>does my code work?"</li>
            </ul></li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>This simple example gives us all the problems of difficult dependencies
    in a nutshell.  Our product code is great, but depends on an external web
    service run by a third party.  It could be slow to contact, it could be
    unavailable.  But even when it is working, it is impossible to predict what
    values it will return.  The whole point of this function is to give us
    real-world data as of the current moment, so how can you write a test that
    proves it is working properly?  You don't know in advance what values it
    will produce.</p>

    <p>If we actually contact Yahoo as part of our testing, then we are testing
    whether Yahoo is working properly as well as our own code.  We want to only
    test our own code.  Our test should tell us, if Yahoo is working properly,
    will our code work properly?</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Fake implementation of current_prices</h1>
    <!--[[[cog include_file("test_port7.py", start=48)   ]]] {{{ -->
    <pre class='python'>
    # Replace Portfolio.current_prices with a stub implementation.
    # This avoids the web, but also skips all our current_prices
    # code.
    class PortfolioValueTest(unittest.TestCase):
        def fake_current_prices(self):
            return {'IBM': 140.0, 'HPQ': 32.0}

        def setUp(self):
            self.p = Portfolio()
            self.p.buy("IBM", 100, 120.0)
            self.p.buy("HPQ", 100, 30.0)
            self.p.current_prices = self.fake_current_prices

        def test_value(self):
            self.assertEqual(self.p.value(), 17200)
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="good">Good: test results are predictable</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Our first test double will be a fake implementation of current_prices().
    In our setUp function, we create a Portfolio, and then we give it a
    new current_prices method that simply returns a fixed value:</p>

<!--[[[cog include_file("test_port7.py", start=48, px=True) ]]] {{{ -->
<code lang='python'>
# Replace Portfolio.current_prices with a stub implementation.
# This avoids the web, but also skips all our current_prices
# code.
class PortfolioValueTest(unittest.TestCase):
    def fake_current_prices(self):
        return {'IBM': 140.0, 'HPQ': 32.0}

    def setUp(self):
        self.p = Portfolio()
        self.p.buy("IBM", 100, 120.0)
        self.p.buy("HPQ", 100, 30.0)
        self.p.current_prices = self.fake_current_prices

    def test_value(self):
        self.assertEqual(self.p.value(), 17200)
</code>
<!--[[[end]]] }}}-->

    <p>This is very simple, and neatly solves a number of our problems: the
    code no longer contacts Yahoo, so it is fast and reliable, and it always
    produces the same value, so we can predict what values our .value() method
    should return.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>But some code isn't tested!</h1>
    <!--[[[cog include_file("test_port7.out", start=7, end=13, highlight=[10])   ]]] {{{ -->
    <pre class='text'>
    $ coverage report -m
    Name            Stmts   Miss  Cover   Missing
    ---------------------------------------------
    portfolio3.py      31      4    87%   53-56
    test_port7.py      44      0   100%
    ---------------------------------------------
    TOTAL              75      4    95%
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("portfolio3.py", start=51, end=61, highlight=[53,54,55,56])   ]]] {{{ -->
    <pre class='python'>
    def current_prices(self):
        """Return a dict mapping names to current prices."""
        url = "http://finance.yahoo.com/d/quotes.csv?f=sl1&amp;s="
        url += ",".join(sorted(s[0] for s in self.stocks))
        data = urllib.urlopen(url)
        return { sym: float(last) for sym, last in csv.reader(data) }

    def value(self):
        """Return the current value of the portfolio."""
        prices = self.current_prices()
        total = 0.0
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>But we may have gone too far: none of our actual current_prices() method
    is tested now.  Here I've used <a href="http://nedbatchelder.com/code/coverage">coverage.py</a>
    to measure what product lines are executed during testing, and it shows us
    that lines 53 through 56 are not executed.  Those are the body of the
    current_prices() method.</p>

    <p>That's our code, and we need to test it somehow.  We got isolation from
    Yahoo, but we removed some of our own code in the process.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Fake urllib.urlopen instead</h1>
    <!--[[[cog include_file("test_port8.py", section="fake")   ]]] {{{ -->
    <pre class='python'>
    # A simple fake for urllib that implements only one method,
    # and is only good for one request.  You can make this much
    # more complex for your own needs.
    class FakeUrllib(object):
        def urlopen(self, url):
            return StringIO('"IBM",140\n"HPQ",32\n')

    class PortfolioValueTest(unittest.TestCase):
        def setUp(self):
            # Save the real urllib, and install our fake.
            self.old_urllib = portfolio3.urllib
            portfolio3.urllib = FakeUrllib()

            self.p = Portfolio()
            self.p.buy("IBM", 100, 120.0)
            self.p.buy("HPQ", 100, 30.0)

        def test_value(self):
            self.assertEqual(self.p.value(), 17200)

        def tearDown(self):
            # Restore the real urllib.
            portfolio3.urllib = self.old_urllib
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>To test our code but still not use Yahoo, we can intercept the flow
    lower down.  Our current_prices() method uses the urllib module to make
    the HTTP request to Yahoo.  We can replace urllib to let our code run,
    but not make a real network request.</p>

    <p>Here we define a class called FakeUrlLib with a method called urlopen
    that will be the test double for urllib.urlopen().  Our fake implementation
    simply returns a file object that provides the same stream of bytes that
    Yahoo would have returned:</p>

<!--[[[cog include_file("test_port8.py", section="fake", px=True) ]]] {{{ -->
<code lang='python'>
# A simple fake for urllib that implements only one method,
# and is only good for one request.  You can make this much
# more complex for your own needs.
class FakeUrllib(object):
    def urlopen(self, url):
        return StringIO('"IBM",140\n"HPQ",32\n')

class PortfolioValueTest(unittest.TestCase):
    def setUp(self):
        # Save the real urllib, and install our fake.
        self.old_urllib = portfolio3.urllib
        portfolio3.urllib = FakeUrllib()

        self.p = Portfolio()
        self.p.buy("IBM", 100, 120.0)
        self.p.buy("HPQ", 100, 30.0)

    def test_value(self):
        self.assertEqual(self.p.value(), 17200)

    def tearDown(self):
        # Restore the real urllib.
        portfolio3.urllib = self.old_urllib
</code>
<!--[[[end]]] }}}-->

    <p>In our test's setUp() method, we replace the urllib reference in our
    product code with our fake implementation.  When the test method runs,
    our FakeUrlLib object will be invoked instead of the urllib module, it will
    return its canned response, and our code will process it just as if it had
    come from Yahoo.</p>

    <p>Notice that the product code uses a module with a function, and we are
    replacing it with an object with a method.  That's fine, Python's dynamic
    nature means that it doesn't matter what "urllib" is defined as, so long as
    it has a .urlopen attribute that is callable, the product code will be
    fine.</p>

    <p>This sort of manipulation is one place where Python really shines, since
    types and access protection don't constrain what we can do to create the
    test environment we want.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>All of our code is executed</h1>
    <!--[[[cog include_file("test_port8.out", start=7, end=13)   ]]] {{{ -->
    <pre class='text'>
    $ coverage report -m
    Name            Stmts   Miss  Cover   Missing
    ---------------------------------------------
    portfolio3.py      31      0   100%
    test_port8.py      50      0   100%
    ---------------------------------------------
    TOTAL              81      0   100%
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="good">Stdlib is stubbed</li>
        <li class="good">All our code is run</li>
        <li class="good">No web access during tests</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Now the coverage report shows that all of our code has been executed.
    By stubbing the standard library, we cut off the component dependencies
    at just the right point: where our code (current_prices) started calling
    someone else's code (urllib.urlopen).</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Even better: mock objects</h1>
    <ul>
        <li>Automatic chameleons</li>
        <li>Act like any object</li>
        <li>Record what happened to them</li>
        <li>You can make assertions afterward</li>
    </ul>
    <!-- ** Interactive session {{{ -->
    <!--[[[cog
    prompt_session("""\
        from mock import Mock

        func = Mock()
        func.return_value = "Hello!"

        func(17, "something")

        func.call_args
        """)
    ]]]-->
    <pre class='python console'>
    &gt;&gt;&gt; from mock import Mock
    Traceback (most recent call last):
      File "&lt;console&gt;", line 1, in &lt;module&gt;
    ModuleNotFoundError: No module named 'mock'

    &gt;&gt;&gt; func = Mock()
    Traceback (most recent call last):
      File "&lt;console&gt;", line 1, in &lt;module&gt;
    NameError: name 'Mock' is not defined
    &gt;&gt;&gt; func.return_value = "Hello!"
    Traceback (most recent call last):
      File "&lt;console&gt;", line 1, in &lt;module&gt;
    NameError: name 'func' is not defined

    &gt;&gt;&gt; func(17, "something")
    Traceback (most recent call last):
      File "&lt;console&gt;", line 1, in &lt;module&gt;
    NameError: name 'func' is not defined

    &gt;&gt;&gt; func.call_args
    Traceback (most recent call last):
      File "&lt;console&gt;", line 1, in &lt;module&gt;
    NameError: name 'func' is not defined
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>A more powerful way to create test doubles is with Mock objects.
    The mock library (third-party for 2.7, in the standard library for 3.3)
    provides the Mock class.  This object will happily act like any object
    you please.  You can set a return_value on it, and when called, it will
    return that value.  Then you can ask what arguments it was called with.</p>

    <p>Mock objects can do other magic things, but these two behaviors give us
    what we need for now.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Mocking with no setup</h1>
    <!--[[[cog include_file("test_port9.py", section="mock")   ]]] {{{ -->
    <pre class='python'>
    class PortfolioValueTest(unittest.TestCase):
        def setUp(self):
            self.p = Portfolio()
            self.p.buy("IBM", 100, 120.0)
            self.p.buy("HPQ", 100, 30.0)

        def test_value(self):
            # Create a mock urllib.urlopen.
            with mock.patch('urllib.urlopen') as urlopen:

                # When called, it will return this value:
                fake_yahoo = StringIO('"IBM",140\n"HPQ",32\n')
                urlopen.return_value = fake_yahoo

                # Run the test!
                self.assertEqual(self.p.value(), 17200)

                # We can ask the mock what its arguments were.
                urlopen.assert_called_with(
                    "http://finance.yahoo.com/d/quotes.csv"
                    "?f=sl1&amp;s=HPQ,IBM"
                    )
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>Here's a new test of our current_prices code:</p>

<!--[[[cog include_file("test_port9.py", section="mock", px=True) ]]] {{{ -->
<code lang='python'>
class PortfolioValueTest(unittest.TestCase):
    def setUp(self):
        self.p = Portfolio()
        self.p.buy("IBM", 100, 120.0)
        self.p.buy("HPQ", 100, 30.0)

    def test_value(self):
        # Create a mock urllib.urlopen.
        with mock.patch('urllib.urlopen') as urlopen:

            # When called, it will return this value:
            fake_yahoo = StringIO('"IBM",140\n"HPQ",32\n')
            urlopen.return_value = fake_yahoo

            # Run the test!
            self.assertEqual(self.p.value(), 17200)

            # We can ask the mock what its arguments were.
            urlopen.assert_called_with(
                "http://finance.yahoo.com/d/quotes.csv"
                "?f=sl1&amp;s=HPQ,IBM"
                )
</code>
<!--[[[end]]] }}}-->

    <p>In our test method, we use a context manager provided by mock:
    mock.patch will replace the given name with a mock object, and give us the
    mock object so we can manipulate it.</p>

    <p>We mock out urllib.urlopen, and then set the value it should return. We
    use the same open file object that we did in the last example, which just
    mimics the bytes that Yahoo would return to us.</p>

    <p>Then we can run the product code, which will call current_prices, which
    will call urllib.urlopen, which is now our mock object.  It will return our
    mocked return value, and produce the expected portfolio value.</p>

    <p>Mock objects also have a handy method on them called
    .assert_called_with() that let us make assertions about the arguments the
    mock object was passed.  This gives us certainty that our code called the
    external component properly.</p>

    <p>When the with statement ends, the mock.patch context manager cleans up,
    restoring urllib.urlopen to it original value.</p>

    <p>The net result is a clean self-contained test double, with assertions
    about how it was called.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Test doubles</h1>
    <ul>
        <li class="incremental">Powerful: isolates code</li>
        <li class="incremental">Focuses tests</li>
        <li class="incremental">Removes speed bumps and randomness</li>
        <li class="incremental">BUT: fragile tests!</li>
        <li class="incremental">Also: "dependency injection"</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Test doubles are a big topic all of their own.  I wanted to give you a
    quick taste of what they are and what they can do.  Using them will
    dramatically improve the isolation, and therefore the speed and usefulness
    of your tests.</p>

    <p>Notice though, that they also make our tests more fragile.  I tested
    current_prices by mocking urllib.urlopen, which only works because I knew
    that current_prices called urlopen.  If I later change the implementation
    of current_prices to access the URL differently, my test will break.</p>

    <p>Finding the right way to use test doubles is a very tricky problem,
    involving tradeoffs between what code is tested, and how dependent on the
    implementation you want to be.</p>

    <p>Another test double technique is "dependency injection," where your code
    is given explicit references to the components it relies on.  This way, the
    dependencies are made more visible.  This also makes them more visible to
    the non-test callers of the code, which you might not want.  But it can
    also make the code more modular, since it has fewer implicit connections to
    other components.  Again, this is a tradeoff, and you have to choose
    carefully how deeply to use the technique.</p>

</div><!-- }}} -->

<!-- }}} -->

<!-- *** Other topics {{{ -->

<div class="slide section" data-layout="clean">
    <h1>Also</h1>
    <h2>Too many things I couldn't fit!</h2>
</div>

<div class="text"><!-- {{{ -->
    <p>Testing is a huge topic, there are many paths to take from here.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Tools</h1>
    <h3 class="incremental">coverage: <span style="font-weight: normal">you'll wonder how you lived without it</span></h3>
    <h3 class="incremental">doctest: <span style="font-weight: normal">only for testing docs!!!</span></h3>
    <h3 class="incremental">ddt: <span style="font-weight: normal">data-driven tests</span></h3>
    <h3 class="incremental">Selenium: <span style="font-weight: normal">in-browser testing</span></h3>
    <h3 class="incremental">Jenkins, Travis, CircleCI: <span style="font-weight: normal">run tests all the time</span></h3>
    <h3 class="incremental">tox: <span style="font-weight: normal">test multiple configurations</span></h3>
</div>

<div class="text"><!-- {{{ -->
    <p>Other tools:</p>

    <ul>

        <li><a href='https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup'>addCleanup</a> 
        is a method on test cases.  It lets you register clean up functions to
        be called when the test is done.  This has the advantage that partially
        set up tests can be torn down, and you can register clean up functions
        in the body of tests if you like.</li>
        
        <li><a href='https://docs.python.org/2/library/doctest.html'>doctest</a>
        is another module in the standard library for writing tests.  It
        executes Python code embedded in docstrings.  Some people love it, but
        most developers think it should only be used for testing code that
        naturally appears in docstrings, and not for anything else.</li>

        <li><a href='https://nose.readthedocs.org/'>nose</a> and
        <a href='http://pytest.org'>py.test</a> are alternative test runners.
        They will run your unittest tests, but have a ton of extra features,
        and plugins.</li>

        <li><a href='http://ddt.readthedocs.org'>ddt</a> is a package for
        writing data-driven tests.  This lets you write one test method, then
        feed it a number of different data cases, and it will split out your
        test method into a number of methods, one for each data case.  This
        lets each one succeed or fail independently.</li>

        <li><a href='/code/coverage'>coverage.py</a> runs your code, and
        measures which lines executed and which did not.  This is a way of
        testing your tests to see how much of your product code is covered by
        your tests.</li>

        <li><a href='http://docs.seleniumhq.org/'>Selenium</a> is a tool for
        running tests of web sites.  It automates a browser to run your tests
        in an actual browser, so you can incorporate the behavior of Javascript
        code and browser behaviors into your tests.</li>

        <li><a href='http://jenkins-ci.org/'>Jenkins</a> and
        <a href='https://docs.travis-ci.org/'>Travis</a> are
        continuous-integration servers.  They run your test suite
        automatically, for example, whenever you make a commit to your repo.
        Running your tests automatically on a server lets your tests results be
        shared among all collaborators, and historical results kept for
        tracking progress.</li>

    </ul>
</div><!-- }}} -->

<div class="slide">
    <h1>Topics</h1>
    <h3 class="incremental">TDD: <span style="font-weight: normal">tests before code!?</span></h3>
    <h3 class="incremental">BDD: <span style="font-weight: normal">describe external behavior</span></h3>
    <h3 class="incremental">integration tests: <span style="font-weight: normal">bigger chunks</span></h3>
    <h3 class="incremental">load testing: <span style="font-weight: normal">how much traffic is OK?</span></h3>
    <h3 class="incremental">others, I'm sure....<span style="font-weight: normal"></span></h3>
</div>

<div class="text"><!-- {{{ -->
    <p>Other topics:</p>

    <ul>

        <li>Test-driven development (TDD) is a style of development where you
        write tests before you write your code.  This isn't so much to ensure
        that your code is tested as it is to give you a chance to think hard
        about how your code will be used before you write the code.  Advocates
        of the style claim your code will be better designed as a result, and
        you have the tests as a side-benefit.</li>

        <li>Behavior-driven development (BDD) uses specialized languages such
        as Cucumber and Lettuce to write tests.  These languages provide a
        higher level of description and focus on the external user-visible
        behavior of your product code.</li>

        <li>In this talk, I've focused on unit tests, which try to test as
        small a chunk of code as possible.  Integration tests work on larger
        chunks, after components have been integrated together.  The scale
        continues on to system tests (of the entire system), and acceptance
        tests (user-visible behavior).  There is no crisp distinction between
        these categories, they fall on a spectrum of scale.</li>

        <li>Load testing is the process of generating synthetic traffic to a
        web site or other concurrent system to determine its behavior as the
        traffic load increases.  Specialized tools can help generate the 
        traffic and record response times as the load changes.</li>

    </ul>

    <p>There are plenty of other topics, I wish I had time and space to discuss
    them all!</p>

</div><!-- }}} -->


<!--
<div class="slide">
    <h1>Doctest</h1>
    <ul>
        <li>Run code snippets in docstrings</li>
        <li>Parses console sessions to find tests and results.</li>
        <li>Good for testing code in docs</li>
        <li>Don't use it for testing product code</li>
    </ul>
</div>

-->

<!-- }}} -->


<div class="slide section" data-layout="clean">
    <h1>Summing up</h1>
</div>

<div class="slide">
    <h1>Testing is...</h1>
    <ul class="incremental">
        <li>Complicated</li>
        <li>Important</li>
        <li>Worthy</li>
        <li>Rewarding</li>
    </ul>
    <p class="incremental" style='text-align:right;margin-top:-3em'><img src='happysticks.png' width="50%"/></p>
</div>

<div class="text"><!-- {{{ -->

    <p>I hope this quick introduction has helped orient you in the world of
    testing.  Testing is a complicated pursuit, because it is trying to solve a
    difficult problem: determining if your code works.  If your code is
    anything interesting at all, then it is large and complex and involved, and
    determining how it behaves is a nearly impossible task.</p>

    <p>Writing tests is the process of crafting a program to do this
    impossible thing, so of course it is difficult.  But it needs to be done:
    how else can you know that your code is working, and stays working as you
    change it?</p>

    <p>From a pure engineering standpoint, writing a good test suite can itself
    be rewarding, since it is a technical challenge to study and overcome.</p>

    <p>Here are our two developers, happy and confident at last because they
    have a good set of tests.  (I couldn't get my son to draw me a third
    picture!)</p>
    
</div><!-- }}} -->


<!--
    Things to add:

    - Start writing tests for bugs you find.
    - Changing mindsets is hard.
        - How do you get people on board?
-->

<div class="slide" data-layout="clean">
    <h1 style='text-align: center; margin-top:1em;'>Questions?</h1>
    <h2 style='text-align: center'><span class="punct">http://</span>bit.ly<span class="punct">/</span>pytest2
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    @nedbat</h2>

    <div class="incremental">
    <p style='text-align:right;margin-top:5em;margin-bottom:-1.5em'><img src='dadtoon-mii.png' width="35%"></p>
    <p style='text-align:right; font-size:85%;margin-top:0'>
    <i>Illustrations by Ben Batchelder...</i>
    <!--
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <i>Made with Cog and Slippy</i>
    -->
    </p>
    </div>
</div>

<!-- *** Using unittest {{{ -->

<div class="slide section" data-layout="clean">
    <h1>unittest</h1>
    <h2>Writing tests</h2>
</div>

<div class="slide">
    <h1>unittest</h1>
    <ul>
        <li>Python standard library</li>
        <li>Infrastructure for well-structured tests</li>
        <li>Patterned on xUnit</li>
    </ul>
</div>

<div class="slide">
    <h1>A simple unit test</h1>
    <!--[[[cog include_file("test_port1.py")   ]]] {{{ -->
    <pre class='python'>
    # test_port1.py

    import unittest
    from portfolio1 import Portfolio

    class PortfolioTest(unittest.TestCase):
        def test_buy_one_stock(self):
            p = Portfolio()
            p.buy("IBM", 100, 176.48)
            assert p.cost() == 17648.0
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port1.out")   ]]] {{{ -->
    <pre class='text'>
    $ python -m unittest test_port1
    .
    ------------------------------------------------------------
    Ran 1 test in 0.000s

    OK
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>Here is an actual unit test written with unittest:</p>

<!--[[[cog include_file("test_port1.py", px=True) ]]] {{{ -->
<code lang='python'>
# test_port1.py

import unittest
from portfolio1 import Portfolio

class PortfolioTest(unittest.TestCase):
    def test_buy_one_stock(self):
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        assert p.cost() == 17648.0
</code>
<!--[[[end]]] }}}-->

    <p>Let's look at the structure of the test in detail.</p>

    <p>All tests are written as methods in a new class.  The class is derived
    from unittest.TestCase, and usually has a name with the word Test in it.</p>

    <p>The test methods all must start with the word "test_".  Here we have
    only one, called "test_buy_one_stock".  The body of the method is the test
    itself.  We create a Portfolio, buy 100 shares of IBM, and then make an
    assertion about the resulting cost.</p>

    <p>This is a complete test.  To run it, we use the unittest module as a
    test runner.  "python -m unittest" means, instead of running a Python
    program in a file, run the importable module "unittest" as the main
    program.</p>

    <p>The unittest module accepts a number of forms of command-line arguments
    telling it what to run.  In this case we give it the module name
    "test_port1".  It will import that module, find the test classes and
    methods in it, and run them all.</p>

    <p>We can see from the output that it ran 1 test, and it passed:</p>

<!--[[[cog include_file("test_port1.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port1
.
------------------------------------------------------------
Ran 1 test in 0.000s

OK
</code>
<!--[[[end]]] }}}-->

</div><!-- }}} -->

<div class="slide">
    <h1>Under the covers</h1>
    <!--[[[cog
    include_code("""\
        # unittest runs the tests as if I had written:
        testcase = PortfolioTest()
        try:
            testcase.test_buy_one_stock()
        except AssertionError:
            [record failure]
        else:
            [record success]
    """, lang="python")
    ]]]-->
    <pre class='python'>
    # unittest runs the tests as if I had written:
    testcase = PortfolioTest()
    try:
        testcase.test_buy_one_stock()
    except AssertionError:
        [record failure]
    else:
        [record success]
    </pre>
    <!--[[[end]]]-->
</div>

<div class="text"><!-- {{{ -->
    <p>Our test code is organized a bit differently that you might have
    expected.  To help understand why, this is what the test runner does to
    execute your tests.</p>

    <p>To run a test, unittest creates an instance of your test case class.
    Then it executes the test method on that object.  It wraps the execution
    in a try/except clause so that assertion failures will be recorded as test
    failures, and if no exception happens, it's recorded as a succcess.</p>

</div><!-- }}} -->

<div class="slide" data-layout="clean">
    <h1>Add more tests</h1>
    <!--[[[cog include_file("test_port2.py", start=6, end=20)   ]]] {{{ -->
    <pre class='python'>
    class PortfolioTest(unittest.TestCase):
        def test_empty(self):
            p = Portfolio()
            assert p.cost() == 0.0

        def test_buy_one_stock(self):
            p = Portfolio()
            p.buy("IBM", 100, 176.48)
            assert p.cost() == 17648.0

        def test_buy_two_stocks(self):
            p = Portfolio()
            p.buy("IBM", 100, 176.48)
            p.buy("HPQ", 100, 36.15)
            assert p.cost() == 21263.0
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port2.out", highlight=[2])   ]]] {{{ -->
    <pre class='text'>
    $ python -m unittest test_port2
    ...
    ------------------------------------------------------------
    Ran 3 tests in 0.000s

    OK
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li>A dot for every passed test</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>One test isn't enough, let's add some more.  Here we add a simpler test,
    test_empty, and a more complicated test, test_buy_two_stocks.  Each test is
    another test method in our PortfolioTest class:</p>

<!--[[[cog include_file("test_port2.py", px=True) ]]] {{{ -->
<code lang='python'>
# test_port2.py

import unittest
from portfolio1 import Portfolio

class PortfolioTest(unittest.TestCase):
    def test_empty(self):
        p = Portfolio()
        assert p.cost() == 0.0

    def test_buy_one_stock(self):
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        assert p.cost() == 17648.0

    def test_buy_two_stocks(self):
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        p.buy("HPQ", 100, 36.15)
        assert p.cost() == 21263.0
</code>
<!--[[[end]]] }}}-->

    <p>Each one creates the portfolio object it needs, performs the
    manipulations it wants, and makes assertions about the outcome.</p>

    <p>When you run the tests, it prints a dot for every test that passes,
    which is why you see "..." in the test output here:</p>

<!--[[[cog include_file("test_port2.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port2
...
------------------------------------------------------------
Ran 3 tests in 0.000s

OK
</code>
<!--[[[end]]] }}}-->

</div><!-- }}} -->

<div class="slide" data-layout="clean">
    <h1>Under the covers</h1>
    <!--[[[cog
    include_code("""\
        # unittest runs the tests as if I had written:
        testcase = PortfolioTest()
        try:
            testcase.test_empty()
        except AssertionError:
            [record failure]
        else:
            [record success]

        testcase = PortfolioTest()
        try:
            testcase.test_buy_one_stock()
        except AssertionError:
            [record failure]
        else:
            [record success]

        testcase = PortfolioTest()
        try:
            testcase.test_buy_two_stocks()
        except AssertionError:
            [record failure]
        else:
            [record success]
    """, lang="python", highlight=[4, 12, 20])
    ]]]-->
    <pre class='python'>
    # unittest runs the tests as if I had written:
    testcase = PortfolioTest()
    try:
        testcase.test_empty()
    except AssertionError:
        [record failure]
    else:
        [record success]

    testcase = PortfolioTest()
    try:
        testcase.test_buy_one_stock()
    except AssertionError:
        [record failure]
    else:
        [record success]

    testcase = PortfolioTest()
    try:
        testcase.test_buy_two_stocks()
    except AssertionError:
        [record failure]
    else:
        [record success]
    </pre>
    <!--[[[end]]]-->
</div>

<div class="text"><!-- {{{ -->
    <p>With three tests, the execution model is much as before.  The key
    thing to note here is that a new instance of PortfolioTest is created
    for each test method.  This helps to guarantee an important property of
    good tests: isolation.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Test isolation</h1>
    <ul>
        <li>Every test gets a new test object</li>
        <li>Tests can't affect each other</li>
        <li>Failure doesn't stop next tests</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>Test isolation means that each of your tests is unaffected by every
    other test. This is good because it makes your tests more repeatable, and
    they are clearer about what they are testing. It also means that if a
    test fails, you don't have to think about all the conditions and data
    created by earlier tests: running just that one test will reproduce the
    failure.</p>

    <p>Earlier we had a problem where one test failing prevented the other
    tests from running.  Here unittest is running each test independently, so
    if one fails, the rest will run, and will run just as if the earlier test
    had succeeded.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>What failure looks like</h1>
    <!--[[[cog include_file("test_port2_broken.out")   ]]] {{{ -->
    <pre class='text'>
    $ python -m unittest test_port2_broken
    F..
    ============================================================
    FAIL: test_buy_one_stock (test_port2_broken.PortfolioTest)
    ------------------------------------------------------------
    Traceback (most recent call last):
      File "/Users/ned/prz/test0/test_port2_broken.py", line 14, in test_buy_one_stock
        assert p.cost() == 17648.0
    AssertionError

    ------------------------------------------------------------
    Ran 3 tests in 0.001s

    FAILED (failures=1)
    </pre>
    <!--[[[end]]] }}}-->
    <ul>
        <li class="good">Better: failed test didn't stop others</li>
        <li class="bad">Bad: what value was returned?</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>So far, all of our tests have passed.  What happens when they fail?</p>

<!--[[[cog include_file("test_port2_broken.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port2_broken
F..
============================================================
FAIL: test_buy_one_stock (test_port2_broken.PortfolioTest)
------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/ned/prz/test0/test_port2_broken.py", line 14, in test_buy_one_stock
    assert p.cost() == 17648.0
AssertionError

------------------------------------------------------------
Ran 3 tests in 0.001s

FAILED (failures=1)
</code>
<!--[[[end]]] }}}-->

    <p>The test runner prints a dot for every test that passes, and it prints
    an "F" for each test failure, so here we see ".F." in the output.  Then
    for each test failure, it prints the name of the test, and the traceback
    of the assertion failure.</p>

    <p>This style of test output means that test successes are very quiet, just
    a single dot.  When a test fails, it stands out, and you can focus on them.
    Remember: when your tests pass, you don't have to do anything, you can go
    on with other work, so passing tests, while a good thing, should not cause
    a lot of noise.  It's the failing tests we need to think about.</p>

    <p>It's great that the traceback shows what assertion failed, but notice
    that it doesn't tell us what bad value was returned.  We can see that we
    expected it to be 17648.0, but we don't know what the actual value was.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>unittest assert helpers</h1>
    <p>self.assertEqual(x, y) instead of assert x == y</p>
    <!--[[[cog include_file("test_port3.py", start=11, end=14, highlight=[14])   ]]] {{{ -->
    <pre class='python'>
    def test_buy_one_stock(self):
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        self.assertEqual(p.cost(), 17648.0)
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port3_broken.out", highlight=[9])   ]]] {{{ -->
    <pre class='text'>
    $ python -m unittest test_port3_broken
    F..
    ============================================================
    FAIL: test_buy_one_stock (test_port3_broken.PortfolioTest)
    ------------------------------------------------------------
    Traceback (most recent call last):
      File "/Users/ned/prz/test0/test_port3_broken.py", line 14, in test_buy_one_stock
        self.assertEqual(p.cost(), 17648.0)
    AssertionError: 17600.0 != 17648.0

    ------------------------------------------------------------
    Ran 3 tests in 0.001s

    FAILED (failures=1)
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>One of the reasons to derive your test classes from unittest.TestCase
    is that it provides you with specialized assertion methods.  Here we
    rewrite our assertion using one of those methods:</p>

<!--[[[cog include_file("test_port3.py", px=True, start=11, end=14) ]]] {{{ -->
<code lang='python'>
def test_buy_one_stock(self):
    p = Portfolio()
    p.buy("IBM", 100, 176.48)
    self.assertEqual(p.cost(), 17648.0)
</code>
<!--[[[end]]] }}}-->

    <p>In this test, we've used self.assertEqual instead of the built-in
    assert statement.  The benefit of the method is that it can print both the
    actual and expected values if the test fails.</p>

    <p>Here the assertion error message shows both values.  The best tests
    will give you information you can use to diagnose and debug the problem.
    Here, when comparing two values for equality, we are told not only that
    they are not equal, but also what each value was.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Lots of assert helpers</h1>
    <!--[[[cog
    include_code("""\
        assertEqual(first, second)
        assertNotEqual(first, second)
        assertTrue(expr)
        assertFalse(expr)
        assertIn(first, second)
        assertNotIn(first, second)
        assertIs(first, second)
        assertIsNot(first, second)
        assertAlmostEqual(first, second)
        assertNotAlmostEqual(first, second)
        assertGreater(first, second)
        assertLess(first, second)
        assertRegexpMatches(text, regexp)
        assertRaises(exc_class, func, ...)
        assertSequenceEqual(seq1, seq2)
        assertItemsEqual(seq1, seq2)

        .. etc ..
    """, lang="python")
    ]]]-->
    <pre class='python'>
    assertEqual(first, second)
    assertNotEqual(first, second)
    assertTrue(expr)
    assertFalse(expr)
    assertIn(first, second)
    assertNotIn(first, second)
    assertIs(first, second)
    assertIsNot(first, second)
    assertAlmostEqual(first, second)
    assertNotAlmostEqual(first, second)
    assertGreater(first, second)
    assertLess(first, second)
    assertRegexpMatches(text, regexp)
    assertRaises(exc_class, func, ...)
    assertSequenceEqual(seq1, seq2)
    assertItemsEqual(seq1, seq2)

    .. etc ..
    </pre>
    <!--[[[end]]]-->
</div>

<div class="text"><!-- {{{ -->

    <p>The unittest.TestCase class provides many assertion methods for testing
    many conditions.  Read through the
    <a href='http://docs.python.org/2/library/unittest.html'>unittest documentation</a>
    to familiarize yourself with the variety available.</p>

</div><!-- }}} -->


<div class="slide">
    <h1>Pro tip: your own base class</h1>
    <!--[[[cog include_file("test_port3b.py", start=6)      ]]] {{{ -->
    <pre class='python'>
    class PortfolioTestCase(unittest.TestCase):
        """Base class for all Portfolio tests."""

        def assertCostEqual(self, p, cost):
            """Assert that `p`'s cost is equal to `cost`."""
            self.assertEqual(p.cost(), cost)


    class PortfolioTest(PortfolioTestCase):
        def test_empty(self):
            p = Portfolio()
            self.assertCostEqual(p, 0.0)

        def test_buy_one_stock(self):
            p = Portfolio()
            p.buy("IBM", 100, 176.48)
            self.assertCostEqual(p, 17648.0)

        def test_buy_two_stocks(self):
            p = Portfolio()
            p.buy("IBM", 100, 176.48)
            p.buy("HPQ", 100, 36.15)
            self.assertCostEqual(p, 21263.0)
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>One simple thing you can do that will help as your test code grows,
    is to define your own base class for your test classes.  You derive a new
    test case class from unittest.TestCase, and then derive all your test
    classes from that class.</p>

    <p>This gives you a place that you can add new assert methods, or other
    test helpers.  Here we've defined an assertCostEqual method that is
    specialized for our portfolio testing:</p>

<!--[[[cog include_file("test_port3b.py", px=True, start=6) ]]] {{{ -->
<code lang='python'>
class PortfolioTestCase(unittest.TestCase):
    """Base class for all Portfolio tests."""

    def assertCostEqual(self, p, cost):
        """Assert that `p`'s cost is equal to `cost`."""
        self.assertEqual(p.cost(), cost)


class PortfolioTest(PortfolioTestCase):
    def test_empty(self):
        p = Portfolio()
        self.assertCostEqual(p, 0.0)

    def test_buy_one_stock(self):
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        self.assertCostEqual(p, 17648.0)

    def test_buy_two_stocks(self):
        p = Portfolio()
        p.buy("IBM", 100, 176.48)
        p.buy("HPQ", 100, 36.15)
        self.assertCostEqual(p, 21263.0)
</code>
<!--[[[end]]] }}}-->

    <p>This class only has a single new method, and that method is pretty
    simple, but we're only testing a small product in this code.  Your real
    system will likely have plenty of opportunities to define domain-specific
    helpers that can make your tests more concise and more readable.</p>

</div><!-- }}} -->


<div class="slide">
    <h1>Third possible outcome: E</h1>
    <p>Test raises an exception</p>
    <!--[[[cog include_file("test_port3_broken2.out", highlight=[2,8,9])   ]]] {{{ -->
    <pre class='text'>
    $ python -m unittest test_port3_broken2
    E..
    ============================================================
    ERROR: test_buy_one_stock (test_port3_broken2.PortfolioTest)
    ------------------------------------------------------------
    Traceback (most recent call last):
      File "/Users/ned/prz/test0/test_port3_broken2.py", line 13, in test_buy_one_stock
        p.buyXX("IBM", 100, 176.48)
    AttributeError: 'Portfolio' object has no attribute 'buyXX'

    ------------------------------------------------------------
    Ran 3 tests in 0.001s

    FAILED (errors=1)
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>There are actually three possible outcomes for a test: passing, failure,
    and error.  Error means that the test raised an exception other than
    AssertionError.  Well-written tests should either succeed, or should fail
    in an assertion.  If another exception happens, it could either mean that
    the test is broken, or that the code is broken, but either way, it isn't
    what you intended.  This condition is marked with an "E", and the error
    stacktrace is displayed:</p>

<!--[[[cog include_file("test_port3_broken2.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port3_broken2
E..
============================================================
ERROR: test_buy_one_stock (test_port3_broken2.PortfolioTest)
------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/ned/prz/test0/test_port3_broken2.py", line 13, in test_buy_one_stock
    p.buyXX("IBM", 100, 176.48)
AttributeError: 'Portfolio' object has no attribute 'buyXX'

------------------------------------------------------------
Ran 3 tests in 0.001s

FAILED (errors=1)
</code>
<!--[[[end]]] }}}-->

    <p>In this case, the mistake is in the test: we tried to call a method
    that doesn't exist.</p>

</div><!-- }}} -->


<div class="hidden_slide">
    <h1>Under the covers</h1>
    <!--[[[cog
    include_code("""\
        testcase = PortfolioTest()
        try:
            testcase.test_method()
        except AssertionError:
            [record failure]
        except:
            [record error]
        else:
            [record success]
    """, lang="python")
    ]]]-->
    <pre class='python'>
    testcase = PortfolioTest()
    try:
        testcase.test_method()
    except AssertionError:
        [record failure]
    except:
        [record error]
    else:
        [record success]
    </pre>
    <!--[[[end]]]-->
</div>

<div class="slide">
    <h1>Can't call the function</h1>
    <!--[[[cog include_file("test_port4_broken.py", start=22, end=24)   ]]] {{{ -->
    <pre class='python'>
    def test_bad_input(self):
        p = Portfolio()
        p.buy("IBM")
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port4_broken.out")   ]]] {{{ -->
    <pre class='text'>
    $ python -m unittest test_port4_broken
    E...
    ============================================================
    ERROR: test_bad_input (test_port4_broken.PortfolioTest)
    ------------------------------------------------------------
    Traceback (most recent call last):
      File "/Users/ned/prz/test0/test_port4_broken.py", line 24, in test_bad_input
        p.buy("IBM")
    TypeError: buy() missing 2 required positional arguments: 'shares' and 'price'

    ------------------------------------------------------------
    Ran 4 tests in 0.000s

    FAILED (errors=1)
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>Here we try to write an automated test of an error case: calling a
    method with too few arguments:</p>

<!--[[[cog include_file("test_port4_broken.py", start=22, end=24, px=True) ]]] {{{ -->
<code lang='python'>
def test_bad_input(self):
    p = Portfolio()
    p.buy("IBM")
</code>
<!--[[[end]]] }}}-->

    <p>This test won't do what we want.  When we call buy() with too few
    arguments, of course it raises TypeError, and there's nothing to catch the
    exception, so the test ends with an Error status:</p>

<!--[[[cog include_file("test_port4_broken.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port4_broken
E...
============================================================
ERROR: test_bad_input (test_port4_broken.PortfolioTest)
------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/ned/prz/test0/test_port4_broken.py", line 24, in test_bad_input
    p.buy("IBM")
TypeError: buy() missing 2 required positional arguments: 'shares' and 'price'

------------------------------------------------------------
Ran 4 tests in 0.000s

FAILED (errors=1)
</code>
<!--[[[end]]] }}}-->

    <p>That's not good, we want all our tests to pass.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>assertRaises</h1>
    <!--[[[cog include_file("test_port4.py", start=22, end=25, highlight=[24,25])   ]]] {{{ -->
    <pre class='python'>
    def test_bad_input(self):
        p = Portfolio()
        with self.assertRaises(TypeError):
            p.buy("IBM")
    </pre>
    <!--[[[end]]] }}}-->
    <!--[[[cog include_file("test_port4.out")   ]]] {{{ -->
    <pre class='text'>
    $ python -m unittest test_port4
    ....
    ------------------------------------------------------------
    Ran 4 tests in 0.000s

    OK
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>To properly handle the error-raising function call, we use a method
    called assertRaises:</p>

<!--[[[cog include_file("test_port4.py", start=22, end=25, px=True) ]]] {{{ -->
<code lang='python'>
def test_bad_input(self):
    p = Portfolio()
    with self.assertRaises(TypeError):
        p.buy("IBM")
</code>
<!--[[[end]]] }}}-->

    <p>This neatly captures our intent: we are asserting that a statement will
    raise an exception.  It's used as a context manager with a "with" statement
    so that it can handle the exception when it is raised:</p>

<!--[[[cog include_file("test_port4.out", px=True) ]]] {{{ -->
<code lang='text'>
$ python -m unittest test_port4
....
------------------------------------------------------------
Ran 4 tests in 0.000s

OK
</code>
<!--[[[end]]] }}}-->

    <p>Now our test passes because the TypeError is caught by the assertRaises
    context manager.  The assertion passes because the exception raised is the
    same type we claimed it would be, and all is well.</p>

    <p>If you have experience with unittest before 2.7, the context manager
    style is new, and much more convenient than the old way.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Portfolio: .sell()</h1>
    <!--[[[cog include_file("portfolio2.py", start=21, end=30)   ]]] {{{ -->
    <pre class='python'>
    def sell(self, name, shares):
        """Sell some shares."""
        for holding in self.stocks:
            if holding[0] == name:
                if holding[1] &lt; shares:
                    raise ValueError("Not enough shares")
                holding[1] -= shares
                break
        else:
            raise ValueError("You don't own that stock")
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>Our testing is going well, time to extend our product.  Let's add
    a .sell() method to our Portfolio class.  It will remove shares of a
    particular stock from our Portfolio:</p>

<!--[[[cog include_file("portfolio2.py", start=21, end=30, px=True) ]]] {{{ -->
<code lang='python'>
def sell(self, name, shares):
    """Sell some shares."""
    for holding in self.stocks:
        if holding[0] == name:
            if holding[1] &lt; shares:
                raise ValueError("Not enough shares")
            holding[1] -= shares
            break
    else:
        raise ValueError("You don't own that stock")
</code>
<!--[[[end]]] }}}-->

    <p>Note: this code is very simple, for the purpose of fitting on a slide!</p>

</div><!-- }}} -->

<div class="slide" data-layout="clean">
    <h1>Testing sell()</h1>
    <!--[[[cog include_file("test_port5.py", start=36)   ]]] {{{ -->
    <pre class='python'>
    class PortfolioSellTest(PortfolioTestCase):
        def test_sell(self):
            p = Portfolio()
            p.buy("MSFT", 100, 27.0)
            p.buy("DELL", 100, 17.0)
            p.buy("ORCL", 100, 34.0)
            p.sell("MSFT", 50)
            self.assertCostEqual(p, 6450)

        def test_not_enough(self):
            p = Portfolio()             # Didn't I just do this?
            p.buy("MSFT", 100, 27.0)
            p.buy("DELL", 100, 17.0)
            p.buy("ORCL", 100, 34.0)
            with self.assertRaises(ValueError):
                p.sell("MSFT", 200)

        def test_dont_own_it(self):
            p = Portfolio()             # What, again!?!?
            p.buy("MSFT", 100, 27.0)
            p.buy("DELL", 100, 17.0)
            p.buy("ORCL", 100, 34.0)
            with self.assertRaises(ValueError):
                p.sell("IBM", 1)
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>To test the .sell() method, we add three more tests.  In each case,
    we need to create a portfolio with some stocks in it so that we have
    something to sell:</p>

<!--[[[cog include_file("test_port5.py", start=36, px=True) ]]] {{{ -->
<code lang='python'>
class PortfolioSellTest(PortfolioTestCase):
    def test_sell(self):
        p = Portfolio()
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        p.sell("MSFT", 50)
        self.assertCostEqual(p, 6450)

    def test_not_enough(self):
        p = Portfolio()             # Didn't I just do this?
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        with self.assertRaises(ValueError):
            p.sell("MSFT", 200)

    def test_dont_own_it(self):
        p = Portfolio()             # What, again!?!?
        p.buy("MSFT", 100, 27.0)
        p.buy("DELL", 100, 17.0)
        p.buy("ORCL", 100, 34.0)
        with self.assertRaises(ValueError):
            p.sell("IBM", 1)
</code>
<!--[[[end]]] }}}-->

    <p>But now our tests are getting really repetitve.  We've used the same
    four lines of code to create the same portfolio object three times.</p>

</div><!-- }}} -->


<div class="slide">
    <h1>Setting up a test</h1>
    <!--[[[cog include_file("test_port6.py", start=36)   ]]] {{{ -->
    <pre class='python'>
    class PortfolioSellTest(PortfolioTestCase):
        # Invoked before each test method
        def setUp(self):
            self.p = Portfolio()
            self.p.buy("MSFT", 100, 27.0)
            self.p.buy("DELL", 100, 17.0)
            self.p.buy("ORCL", 100, 34.0)

        def test_sell(self):
            self.p.sell("MSFT", 50)
            self.assertCostEqual(self.p, 6450)

        def test_not_enough(self):
            with self.assertRaises(ValueError):
                self.p.sell("MSFT", 200)

        def test_dont_own_it(self):
            with self.assertRaises(ValueError):
                self.p.sell("IBM", 1)
    </pre>
    <!--[[[end]]] }}}-->
</div>

<div class="text"><!-- {{{ -->

    <p>This is a common problem, so unittest has a solution for us.  A test
    class can define a .setUp() method.  This method is invoked before each
    test method.  Because your test class is a class, you have a self object
    that you can create attributes on:</p>

<!--[[[cog include_file("test_port6.py", start=36, px=True) ]]] {{{ -->
<code lang='python'>
class PortfolioSellTest(PortfolioTestCase):
    # Invoked before each test method
    def setUp(self):
        self.p = Portfolio()
        self.p.buy("MSFT", 100, 27.0)
        self.p.buy("DELL", 100, 17.0)
        self.p.buy("ORCL", 100, 34.0)

    def test_sell(self):
        self.p.sell("MSFT", 50)
        self.assertCostEqual(self.p, 6450)

    def test_not_enough(self):
        with self.assertRaises(ValueError):
            self.p.sell("MSFT", 200)

    def test_dont_own_it(self):
        with self.assertRaises(ValueError):
            self.p.sell("IBM", 1)
</code>
<!--[[[end]]] }}}-->

    <p>Here we have a .setup() method that creates a portfolio and stores it as
    self.p.  Then the three test methods can simply use the self.p portfolio.
    Note the three test methods are much smaller, since they share the common
    setup code in .setUp().</p>

    <p>Naturally, there's also a .tearDown() method that will be invoked when
    the test method is finished.  tearDown can clean up after a test, for
    example if your setUp created records in a database, or files on disk.  We
    don't need one here.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>Under the covers</h1>
    <!--[[[cog
    include_code("""\
        testcase = PortfolioTest()
        try:
            testcase.setUp()
        except:
            [record error]
        else:
            try:
                testcase.test_method()
            except AssertionError:
                [record failure]
            except:
                [record error]
            else:
                [record success]
            finally:
                try:
                    testcase.tearDown()
                except:
                    [record error]
    """, lang="python", highlight=[3,17])
    ]]]-->
    <pre class='python'>
    testcase = PortfolioTest()
    try:
        testcase.setUp()
    except:
        [record error]
    else:
        try:
            testcase.test_method()
        except AssertionError:
            [record failure]
        except:
            [record error]
        else:
            [record success]
        finally:
            try:
                testcase.tearDown()
            except:
                [record error]
    </pre>
    <!--[[[end]]]-->
</div>

<div class="text"><!-- {{{ -->

    <p>Here's the detail on how unittest runs the setUp, test_method, and
    tearDown methods.  A test case object is instantiated, and its .setUp() is
    run.  if it doesn't raise an exception, then the .test_method() is run,
    noting its outcome.  No matter what happens with the .test_method(), the
    tearDown() is run.</p>

    <p>This is an important reason to put clean up code in a tearDown() method:
    it will be run even if your test fails.  If you try to clean up after
    yourself at the end of your test method, then if the test fails, the
    clean up doesn't happen, and you may pollute other tests.</p>

</div><!-- }}} -->

<div class="slide">
    <h1>setUp and tearDown: isolation!</h1>
    <ul>
        <li>Establish context</li>
        <li>Common pre- or post- work</li>
        <li>Isolation, even with failures</li>
        <li>Also: "fixtures"</li>
    </ul>
</div>

<div class="text"><!-- {{{ -->

    <p>setUp and tearDown are important ways to write more concise tests, and
    more importantly, give you powerful tools for ensuring proper test
    isolation.</p>

    <p>If you find your setUp and tearDown methods getting elaborate, there are
    third party "fixture" libraries that can help automate the creation of
    test data and environments.</p>

</div><!-- }}} -->

<div class="hidden_slide">
    <h1>How NOT to do it</h1>
    <!--[[[cog
    include_code("""\
        class MyBadTestCase(unittest.TestCase):
            def test_a_thing(self):
                old_global = SOME_GLOBAL_THING
                SOME_GLOBAL_THING = new_test_value

                do_my_test_stuff()

                SOME_GLOBAL_THING = old_global
    """, lang="python")
    ]]]-->
    <pre class='python'>
    class MyBadTestCase(unittest.TestCase):
        def test_a_thing(self):
            old_global = SOME_GLOBAL_THING
            SOME_GLOBAL_THING = new_test_value

            do_my_test_stuff()

            SOME_GLOBAL_THING = old_global
    </pre>
    <!--[[[end]]]-->
    <ul>
        <li>Common impulse</li>
        <li>But if test fails, globals aren't restored</li>
    </ul>
</div>

<div class="hidden_slide">
    <h1>The right way</h1>
    <!--[[[cog
    include_code("""\
        class MyGoodTestCase(unittest.TestCase):
            def setUp(self):
                self.old_global = SOME_GLOBAL_THING
                SOME_GLOBAL_THING = new_test_value

            def tearDown(self):
                SOME_GLOBAL_THING = self.old_global

            def test_a_thing(self):
                do_my_test_stuff()
    """, lang="python")
    ]]]-->
    <pre class='python'>
    class MyGoodTestCase(unittest.TestCase):
        def setUp(self):
            self.old_global = SOME_GLOBAL_THING
            SOME_GLOBAL_THING = new_test_value

        def tearDown(self):
            SOME_GLOBAL_THING = self.old_global

        def test_a_thing(self):
            do_my_test_stuff()
    </pre>
    <!--[[[end]]]-->
    <ul>
        <li>tearDown gets run no matter what *</li>
        <li>Reuse: same setUp and tearDown apply to all the test methods</li>
        <li>Test method is small and focused</li>
        <li>* unless setUp fails</li>
    </ul>
</div>

<!-- }}} -->

</body>
</html>
<!-- vim: set foldmethod=marker: -->
